{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anndata as ad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "file = pickle.load(open(\"/work/home/cryoem666/xyf/temp/pycharm/Squidiff/checkpoints/ours_small_test_total2k_gene_new/vocab_state.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 56, 2014)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file['cell_line']), len(file['batch']), len(file['perturb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#squidiff_Data = ad.read_h5ad(\"/work/home/cryoem666/xyf/temp/pycharm/Squidiff/data/diff_data/diff_train.h5ad\")\n",
    "import toml \n",
    "config = toml.load(\"/work/home/cryoem666/xyf/temp/pycharm/Squidiff/data/replogle/hepg2.toml\")\n",
    "state_Data = ad.read_h5ad(config['datasets']['replogle_proper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene_list = config['fewshot']['replogle_proper.hepg2']['val'] + config['fewshot']['replogle_proper.hepg2']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_Data = state_Data[state_Data.obs['gene'].isin(file['perturb'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2014, 56, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file['perturb']), len(file['batch']), len(file['cell_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model and diffusion...\n",
      "{'output_dim': 128, 'num_layers': 3, 'num_channels': 128, 'dropout': 0.0, 'class_cond': False, 'use_checkpoint': False, 'use_scale_shift_norm': True, 'use_fp16': False, 'use_encoder': True, 'state_dataset_config': {'perturb_len': 2014, 'batch_len': 56, 'cell_line_len': 4, 'gene_size': 128, 'output_dim': 128}, 'learn_sigma': False, 'diffusion_steps': 1000, 'noise_schedule': 'linear', 'timestep_respacing': '', 'use_kl': False, 'predict_xstart': False, 'rescale_timesteps': False, 'rescale_learned_sigmas': False, 'data_path': '', 'schedule_sampler': 'uniform', 'lr': 0.0001, 'weight_decay': 0.0, 'lr_anneal_steps': 100000.0, 'batch_size': 16, 'microbatch': -1, 'ema_rate': '0.9999', 'log_interval': 10000.0, 'save_interval': 10000.0, 'resume_checkpoint': '', 'fp16_scale_growth': 0.001, 'use_ddim': True, 'logger_path': '', 'model_path': '/work/home/cryoem666/xyf/temp/pycharm/Squidiff/Squidiff/checkpoints/replogle_train_total_vae_2k/model.pt', 'comb_num': 1, 'drug_dimension': 1024, 'use_vae': True}\n",
      "diffusion num of steps =  1000\n"
     ]
    }
   ],
   "source": [
    "from sympy import use\n",
    "import sample_squidiff_ours\n",
    "sampler = sample_squidiff_ours.sampler(\n",
    "        model_path = '/work/home/cryoem666/xyf/temp/pycharm/Squidiff/Squidiff/checkpoints/replogle_train_total_vae_2k/model.pt',\n",
    "        perturb_len = len(file['perturb']),\n",
    "        batch_len = len(file['batch']),\n",
    "        cell_line_len = len(file['cell_line']),\n",
    "        gene_size = 128,\n",
    "        #gene_size=201,\n",
    "        diffusion_steps = 1000,\n",
    "        use_vae=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "def one_hot(label, key):\n",
    "    vec = np.zeros(len(file[key]), dtype=int)\n",
    "    idx = file[key][label]\n",
    "    vec[idx] = 1\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_211389/1927203975.py:1: ImplicitModificationWarning: Trying to modify attribute `.obs` of view, initializing view as actual.\n",
      "  state_Data.obs['perturb_label'] = state_Data.obs['gene'].apply(lambda x: file['perturb'][x])\n"
     ]
    }
   ],
   "source": [
    "state_Data.obs['perturb_label'] = state_Data.obs['gene'].apply(lambda x: file['perturb'][x])\n",
    "state_Data.obs['batch_label'] = state_Data.obs['gem_group'].apply(lambda x: file['batch'][x])\n",
    "state_Data.obs['cell_line_label'] = state_Data.obs['cell_line'].apply(lambda x: file['cell_line'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/data/state_original_hf_hepg2/adata_pred.h5ad')\n",
    "hepg2_real = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/data/state_original_hf_hepg2/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RPL35', 'HSD17B10', 'GPS1', 'NUP88', 'GCLC', ..., 'ZNF787', 'GTF2H3', 'SETX', 'SDHC', 'VARS2']\n",
       "Length: 381\n",
       "Categories (381, object): ['ABCB7', 'ABHD11', 'ACTR1B', 'ACTR8', ..., 'ZNF787', 'ZNHIT3', 'ZNHIT6', 'non-targeting']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_real.obs['gene'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_Data_train = state_Data[~((state_Data.obs['cell_line']=='hepg2')&(state_Data.obs['gene'].isin(test_gene_list)))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 4976 × 6642\n",
       "    obs: 'gem_group', 'gene', 'gene_id', 'transcript', 'gene_transcript', 'sgID_AB', 'mitopercent', 'UMI_count', 'z_gemgroup_UMI', 'cell_line', 'perturb_label', 'batch_label', 'cell_line_label'\n",
       "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'hvg'\n",
       "    obsm: 'X_hvg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_Data_train[(state_Data_train.obs['cell_line']=='hepg2')&(state_Data_train.obs['gene']=='non-targeting')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [00:21<00:00, 17.89it/s]\n"
     ]
    }
   ],
   "source": [
    "direction_dict = {}\n",
    "direction_total = {}\n",
    "cell_type_list = ['k562', 'jurkat', 'rpe1', 'hepg2']\n",
    "#gene_list = ['CDC20']\n",
    "gene_list = hepg2_real.obs['pert_name'].unique()\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "for gene in tqdm(gene_list):\n",
    "    for cell_type in cell_type_list:\n",
    "        if cell_type == 'hepg2' and gene!='non-targeting' :\n",
    "            continue\n",
    "        key = (gene, cell_type)\n",
    "        case = state_Data_train[(state_Data_train.obs['gene']==gene) & (state_Data_train.obs['cell_line']==cell_type)].copy()\n",
    "        if case.n_obs == 0:\n",
    "            continue\n",
    "        case.obsm['VAE_latent'] = sampler.autoencoder(torch.tensor(case[:, case.var['highly_variable']].X.toarray()).to('cuda'), return_latent=True).detach().cpu().numpy()\n",
    "        z_sem = sampler.model.encoder.forward(\n",
    "            torch.tensor(case.obsm['VAE_latent']).to('cuda'),\n",
    "            cell_type = torch.tensor(np.stack(case.obs['cell_line_label'].values), dtype=torch.int32).to('cuda'),\n",
    "            batch = torch.tensor(np.stack(case.obs['batch_label'].values), dtype=torch.int32).to('cuda'),\n",
    "            perturb_label = torch.tensor(np.stack(case.obs['perturb_label'].values), dtype=torch.int32).to('cuda'),\n",
    "        )\n",
    "        z_sem_mean = z_sem.mean(axis=0).detach().cpu().numpy()\n",
    "        direction_dict[key] = z_sem_mean\n",
    "        direction_total[key] = z_sem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/home/cryoem666/miniconda3/envs/my_state/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/work/home/cryoem666/miniconda3/envs/my_state/lib/python3.12/site-packages/numpy/_core/_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "avg_direction = {}\n",
    "for gene in hepg2_real.obs['gene'].unique():\n",
    "    if gene == 'non-targeting':\n",
    "        continue\n",
    "    control2perturb = [value-direction_dict[('non-targeting', key[1])] for key, value in direction_dict.items() if key[0]==gene]\n",
    "    avg_direction[gene] = np.mean(control2perturb, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.07984416)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "direction_dict[('RPL35','k562')], direction_dict[('RPL35','rpe1')]\n",
    "#Compute cosine similarity between two vectors\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    if norm_vec1 == 0 or norm_vec2 == 0:\n",
    "        return 0.0\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "cosine_similarity(direction_dict[('RPL35','k562')], direction_dict[('RPL35','rpe1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def _median_heuristic(D2):\n",
    "    # D2: [N, N] squared distances\n",
    "    # 去掉对角线 0，取中位数更稳\n",
    "    N = D2.shape[0]\n",
    "    mask = ~torch.eye(N, dtype=torch.bool, device=D2.device)\n",
    "    return torch.median(D2[mask])\n",
    "\n",
    "def mmd_loss(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None, device=\"cuda\"):\n",
    "    source = torch.as_tensor(source, device=device, dtype=torch.float32)\n",
    "    target = torch.as_tensor(target, device=device, dtype=torch.float32)\n",
    "    n, m = source.size(0), target.size(0)\n",
    "    total = torch.cat([source, target], dim=0)  # [N, d]\n",
    "    N = n + m\n",
    "\n",
    "    # [N, N] 欧氏距离；cdist返回的是sqrt的距离，这里平方\n",
    "    D2 = torch.cdist(total, total, p=2) ** 2\n",
    "\n",
    "    if fix_sigma is None:\n",
    "        # 更常用的 median heuristic\n",
    "        sigma2 = _median_heuristic(D2).clamp_min(1e-12)\n",
    "    else:\n",
    "        sigma2 = torch.tensor(fix_sigma, device=device, dtype=torch.float32)\n",
    "\n",
    "    # 多核：sigma2 / kernel_mul^(k//2) 作为基准\n",
    "    base = sigma2 / (kernel_mul ** (kernel_num // 2))\n",
    "    K = 0.0\n",
    "    for i in range(kernel_num):\n",
    "        gamma = base * (kernel_mul ** i)\n",
    "        K = K + torch.exp(-D2 / (2.0 * gamma))\n",
    "\n",
    "    XX = K[:n, :n]\n",
    "    YY = K[n:, n:]\n",
    "    XY = K[:n, n:]\n",
    "    YX = K[n:, :n]\n",
    "    return XX.mean() + YY.mean() - XY.mean() - YX.mean()\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def _spearman_corr_1d(x, y, eps=1e-8):\n",
    "    \"\"\"\n",
    "    x, y: 1D tensor, same length\n",
    "    返回 Spearman 相关系数（标量）\n",
    "    \"\"\"\n",
    "    x = x.float()\n",
    "    y = y.float()\n",
    "\n",
    "    # rank: argsort().argsort() 简单实现，不做复杂 ties 校正\n",
    "    rx = x.argsort().argsort().float()\n",
    "    ry = y.argsort().argsort().float()\n",
    "\n",
    "    rx = rx - rx.mean()\n",
    "    ry = ry - ry.mean()\n",
    "    rx = rx / (rx.std(unbiased=False) + eps)\n",
    "    ry = ry / (ry.std(unbiased=False) + eps)\n",
    "\n",
    "    return (rx * ry).mean()\n",
    "\n",
    "\n",
    "def scc_score(source, target, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    source, target: [..., n_genes]，默认第一维是 cell\n",
    "    建议外面先做好 log-normalization，再丢进来，\n",
    "    对齐 scDiffusion 那种做法。\n",
    "    \"\"\"\n",
    "    source = torch.as_tensor(source, device=device, dtype=torch.float32)\n",
    "    target = torch.as_tensor(target, device=device, dtype=torch.float32)\n",
    "\n",
    "    # [n_genes]，在 cell 维取均值\n",
    "    mu_s = source.mean(dim=0)\n",
    "    mu_t = target.mean(dim=0)\n",
    "\n",
    "    return _spearman_corr_1d(mu_s, mu_t)\n",
    "def lisi_binary(source, target, k=90, device=\"cuda\"):\n",
    "    \"\"\"\n",
    "    kNN 版 iLISI：\n",
    "    - source: [n, d]\n",
    "    - target: [m, d]\n",
    "    - 返回整体平均 LISI，以及 source / target 各自的平均 LISI\n",
    "    \"\"\"\n",
    "    source = torch.as_tensor(source, device=device, dtype=torch.float32)\n",
    "    target = torch.as_tensor(target, device=device, dtype=torch.float32)\n",
    "\n",
    "    n, d = source.shape\n",
    "    m, _ = target.shape\n",
    "\n",
    "    total = torch.cat([source, target], dim=0)  # [N, d]\n",
    "    N = n + m\n",
    "\n",
    "    labels = torch.cat([\n",
    "        torch.zeros(n, device=device, dtype=torch.long),\n",
    "        torch.ones(m, device=device, dtype=torch.long)\n",
    "    ], dim=0)  # 0 = source, 1 = target\n",
    "\n",
    "    # 跟你 MMD 一样，直接用 cdist\n",
    "    D2 = torch.cdist(total, total, p=2) ** 2  # [N, N]\n",
    "\n",
    "    # kNN：取自己之外的最近 k 个\n",
    "    # indices[:, 0] 是自己\n",
    "    knn_idx = D2.topk(k + 1, largest=False).indices[:, 1:]  # [N, k]\n",
    "\n",
    "    knn_labels = labels[knn_idx]  # [N, k]\n",
    "\n",
    "    # one-hot 统计邻居标签分布\n",
    "    num_classes = int(labels.max().item()) + 1  # 应该是 2\n",
    "    one_hot = F.one_hot(knn_labels, num_classes=num_classes).float()  # [N, k, C]\n",
    "\n",
    "    # p_il = 邻居中各 label 的比例\n",
    "    p = one_hot.mean(dim=1)  # [N, C]\n",
    "\n",
    "    # LISI_i = 1 / sum_l p_il^2\n",
    "    lisi_i = 1.0 / (p ** 2).sum(dim=1)  # [N]\n",
    "\n",
    "    # 总体 & 各子集平均\n",
    "    lisi_all = lisi_i.mean()\n",
    "    lisi_source = lisi_i[:n].mean()\n",
    "    lisi_target = lisi_i[n:].mean()\n",
    "\n",
    "    return lisi_all, lisi_source, lisi_target\n",
    "\n",
    "def return_metrics(x, y):\n",
    "    from sklearn.metrics import r2_score\n",
    "    from scipy.stats import pearsonr\n",
    "    return {\"r2_score\": r2_score(x.mean(axis=0), y.mean(axis=0)), \n",
    "            \"pearsonr\": pearsonr(x.mean(axis=0), y.mean(axis=0))[0], \n",
    "            \"mmd\": mmd_loss(x, y), \n",
    "            \"mmd_rbf\": mmd_rbf(x,y)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guassian_kernel(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    n_samples = int(source.size()[0])+int(target.size()[0])\n",
    "    total = torch.cat([source, target], dim=0)\n",
    "\n",
    "    total0 = total.unsqueeze(0).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    total1 = total.unsqueeze(1).expand(int(total.size(0)), int(total.size(0)), int(total.size(1)))\n",
    "    \n",
    "    batch_size = 200\n",
    "    num_window = int(total0.shape[0]/batch_size)+1\n",
    "    L2_dis = []\n",
    "    for i in tqdm(range(num_window)):\n",
    "        diff = (total0[i*batch_size:(i+1)*batch_size].cuda()-total1[i*batch_size:(i+1)*batch_size].cuda())\n",
    "        diff.square_()\n",
    "        L2_dis.append(diff.sum(2).cpu())\n",
    "    L2_distance = torch.concatenate(L2_dis,dim=0)\n",
    "\n",
    "\n",
    "    if fix_sigma:\n",
    "        bandwidth = fix_sigma\n",
    "    else:\n",
    "        bandwidth = torch.sum(L2_distance.data) / (n_samples**2-n_samples)\n",
    "\n",
    "    bandwidth /= kernel_mul ** (kernel_num // 2)\n",
    "    bandwidth_list = [bandwidth * (kernel_mul**i) for i in range(kernel_num)]\n",
    "\n",
    "    kernel_val = [torch.exp(-L2_distance / bandwidth_temp) for bandwidth_temp in bandwidth_list]\n",
    "\n",
    "    return sum(kernel_val)#/len(kernel_val)\n",
    "\n",
    "def mmd_rbf(source, target, kernel_mul=2.0, kernel_num=5, fix_sigma=None):\n",
    "    source = torch.as_tensor(source, dtype=torch.float32).cuda()\n",
    "    target = torch.as_tensor(target, dtype=torch.float32).cuda()\n",
    "    batch_size = int(source.size()[0])\n",
    "    kernels = guassian_kernel(source, target,\n",
    "        kernel_mul=kernel_mul, kernel_num=kernel_num, fix_sigma=fix_sigma)\n",
    "\n",
    "    XX = kernels[:batch_size, :batch_size]\n",
    "    YY = kernels[batch_size:, batch_size:]\n",
    "    XY = kernels[:batch_size, batch_size:]\n",
    "    YX = kernels[batch_size:, :batch_size]\n",
    "    loss = torch.mean(XX + YY - XY -YX)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "case = state_Data_train[(state_Data_train.obs['cell_line']=='hepg2')&(state_Data_train.obs['gene']=='non-targeting')]\n",
    "hepg2_pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/cpa_replogle_v2/fold1/adata_pred.h5ad')\n",
    "hepg2_real = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/cpa_replogle_v2/fold1/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.88s/it]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "pert = random.choice(hepg2_real.obs['pert_name'].unique())\n",
    "#pert = 'non-targeting'\n",
    "hepg2_real_sample = hepg2_real[hepg2_real.obs['pert_name']==pert].copy()\n",
    "hepg2_pred_sample = hepg2_pred[hepg2_pred.obs['pert_name']==pert].copy()\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 预分配 obsm\n",
    "hepg2_real_sample.obsm['X_squidiff_ours'] = np.zeros((hepg2_real_sample.n_obs, 2000), dtype=np.float32)\n",
    "\n",
    "# 2) 准备常量（放 GPU 一次就好）\n",
    "base_control = torch.as_tensor(\n",
    "    direction_dict[('non-targeting','hepg2')],\n",
    "    device='cuda',\n",
    "    dtype=torch.float32\n",
    ")  # [128]\n",
    "\n",
    "for gene in tqdm(hepg2_real_sample.obs['pert_name'].unique()):\n",
    "    mask = (hepg2_real_sample.obs['pert_name'].values == gene)\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        continue\n",
    "    \n",
    "    if gene == 'non-targeting':\n",
    "        scrna_pred = hepg2_real_sample.X[mask]\n",
    "        hepg2_real_sample.obsm['X_squidiff_ours'][mask] = scrna_pred\n",
    "        continue\n",
    "    '''\n",
    "    if gene == 'non-targeting':\n",
    "        new_direction = torch.zeros(60, device='cuda', dtype=torch.float32)\n",
    "    '''    \n",
    "    new_direction = torch.as_tensor(avg_direction[gene], device='cuda', dtype=torch.float32)  # [128]\n",
    "    # [n, 128]\n",
    "    z_sem_origin = base_control.unsqueeze(0).expand(n, -1).contiguous()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scrna_pred = sampler.interp_with_direction(\n",
    "            z_sem_origin=z_sem_origin,\n",
    "            gene_size=128,\n",
    "            direction=new_direction,\n",
    "            scale=1,\n",
    "            add_noise_term=False\n",
    "        )\n",
    "        '''\n",
    "        scrna_pred_new = sampler.pred(\n",
    "            z_sem = z_sem_origin,\n",
    "            gene_size = 128\n",
    "        )\n",
    "        '''\n",
    "\n",
    "    hepg2_real_sample.obsm['X_squidiff_ours'][mask] = scrna_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_211389/1963521033.py:2: ImplicitModificationWarning: Setting element `.obsm['VAE_latent']` of view, initializing view as actual.\n",
      "  non_targeting_hepg2.obsm['VAE_latent'] = sampler.autoencoder(torch.tensor(non_targeting_hepg2[:, non_targeting_hepg2.var['highly_variable']].X.toarray()).to('cuda'), return_latent=True).detach().cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "non_targeting_hepg2 = state_Data_train[(state_Data_train.obs['cell_line']=='hepg2')&(state_Data_train.obs['gene']=='non-targeting')]\n",
    "non_targeting_hepg2.obsm['VAE_latent'] = sampler.autoencoder(torch.tensor(non_targeting_hepg2[:, non_targeting_hepg2.var['highly_variable']].X.toarray()).to('cuda'), return_latent=True).detach().cpu().numpy()\n",
    "z_sem = sampler.model.encoder(\n",
    "    torch.tensor(non_targeting_hepg2.obsm['VAE_latent']).to('cuda'),\n",
    "    cell_type = torch.tensor(np.stack(non_targeting_hepg2.obs['cell_line_label'].values), dtype=torch.int32).to('cuda'),\n",
    "    batch = torch.tensor(np.stack(non_targeting_hepg2.obs['batch_label'].values), dtype=torch.int32).to('cuda'),\n",
    "    perturb_label = torch.tensor(np.stack(non_targeting_hepg2.obs['perturb_label'].values), dtype=torch.int32).to('cuda')\n",
    ")\n",
    "pred = sampler.pred(\n",
    "    z_sem = z_sem,\n",
    "    gene_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnnData object with n_obs × n_vars = 4976 × 6642\n",
       "    obs: 'gem_group', 'gene', 'gene_id', 'transcript', 'gene_transcript', 'sgID_AB', 'mitopercent', 'UMI_count', 'z_gemgroup_UMI', 'cell_line', 'perturb_label', 'batch_label', 'cell_line_label'\n",
       "    var: 'highly_variable', 'means', 'dispersions', 'dispersions_norm'\n",
       "    uns: 'hvg'\n",
       "    obsm: 'X_hvg', 'VAE_latent'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "non_targeting_hepg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 824.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'r2_score': 0.9749298095703125,\n",
       " 'pearsonr': np.float32(0.9881098),\n",
       " 'mmd': tensor(0.9742, device='cuda:0'),\n",
       " 'mmd_rbf': tensor(1.4266)}"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_metrics(hepg2_real_sample.X, hepg2_real_sample.obsm['X_squidiff_ours'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [16:41<00:00,  2.63s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 预分配 obsm\n",
    "hepg2_real.obsm['X_squidiff_ours'] = np.zeros((hepg2_real.n_obs, 2000), dtype=np.float32)\n",
    "\n",
    "# 2) 准备常量（放 GPU 一次就好）\n",
    "base_control = torch.as_tensor(\n",
    "    direction_dict[('non-targeting','hepg2')],\n",
    "    device='cuda',\n",
    "    dtype=torch.float32\n",
    ")  # [128]\n",
    "\n",
    "for gene in tqdm(hepg2_real.obs['pert_name'].unique()):\n",
    "    mask = (hepg2_real.obs['pert_name'].values == gene)\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        continue\n",
    "    if gene == 'non-targeting':\n",
    "        scrna_pred = hepg2_real.X[mask]\n",
    "        hepg2_real.obsm['X_squidiff_ours'][mask] = scrna_pred\n",
    "        continue\n",
    "    new_direction = torch.as_tensor(avg_direction[gene], device='cuda', dtype=torch.float32)  # [128]\n",
    "\n",
    "    # [n, 128]\n",
    "    z_sem_origin = base_control.unsqueeze(0).expand(n, -1).contiguous()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        scrna_pred = sampler.interp_with_direction(\n",
    "            z_sem_origin=z_sem_origin,\n",
    "            gene_size=128,\n",
    "            direction=new_direction,\n",
    "            scale=1\n",
    "        )\n",
    "\n",
    "    scrna_pred = scrna_pred\n",
    "    hepg2_real.obsm['X_squidiff_ours'][mask] = scrna_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 381/381 [16:34<00:00,  2.61s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1) 预分配 obsm\n",
    "hepg2_real.obsm['X_squidiff_ours'] = np.zeros((hepg2_real.n_obs, 2000), dtype=np.float32)\n",
    "\n",
    "# 2) 准备常量（放 GPU 一次就好）\n",
    "base_control = torch.as_tensor(\n",
    "    direction_dict[('non-targeting','hepg2')],\n",
    "    device='cuda',\n",
    "    dtype=torch.float32\n",
    ")  # [128]\n",
    "\n",
    "for gene in tqdm(hepg2_real.obs['pert_name'].unique()):\n",
    "    mask = (hepg2_real.obs['pert_name'].values == gene)\n",
    "    n = int(mask.sum())\n",
    "    if n == 0:\n",
    "        continue\n",
    "    if gene == 'non-targeting':\n",
    "        scrna_pred = hepg2_real.X[mask]\n",
    "        hepg2_real.obsm['X_squidiff_ours'][mask] = scrna_pred\n",
    "        continue\n",
    "    new_direction = torch.as_tensor(avg_direction[gene], device='cuda', dtype=torch.float32)  # [128]\n",
    "    # [n, 128]\n",
    "    z_sem_origin = base_control.unsqueeze(0).expand(n, -1).contiguous()\n",
    "    with torch.no_grad():\n",
    "        if isinstance(np.isnan(avg_direction[gene]),np.bool_):\n",
    "            scrna_pred = sampler.pred(\n",
    "                z_sem = z_sem_origin,\n",
    "                gene_size = 128\n",
    "            )\n",
    "        else:\n",
    "            scrna_pred = sampler.interp_with_direction(\n",
    "                z_sem_origin=z_sem_origin,\n",
    "                gene_size=128,\n",
    "                direction=new_direction,\n",
    "                scale=0.5,\n",
    "                add_noise_term = False\n",
    "            )\n",
    "\n",
    "    scrna_pred = scrna_pred\n",
    "    hepg2_real.obsm['X_squidiff_ours'][mask] = scrna_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.3019072, 0.8493603, 0.       , ..., 4.7882867, 3.415735 ,\n",
       "       0.8493603], shape=(2000,), dtype=float32)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(np.isnan(avg_direction['CDC20']),np.bool_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CDC20', 'NOS1AP', 'SLC16A5', 'CMTR2', 'CACTIN', 'SPAG7', 'MRM1', 'LAMB1']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item in list(hepg2_real.obs['pert_name'].unique()) if item!='non-targeting' and isinstance(np.isnan(avg_direction[item]),np.bool_)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_list = [item for item in list(hepg2_real.obs['pert_name'].unique()) if item!='non-targeting' and isinstance(np.isnan(avg_direction[item]),np.bool_)]\n",
    "for gene in nan_list:\n",
    "    hepg2_new.X[hepg2_new.obs['pert_name']==gene] = hepg2_real.X[hepg2_real.obs['pert_name']==gene]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_new = hepg2_real.copy()\n",
    "hepg2_new.X = hepg2_new.obsm['X_squidiff_ours']\n",
    "hepg2_new.obsm = {}\n",
    "hepg2_real.obsm = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_count = np.isnan(hepg2_new.X).sum()\n",
    "nan_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31842, 2000)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_new.X[12:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7051982 , 0.91662085, 0.        , ..., 5.165333  , 2.94496   ,\n",
       "        0.91662085],\n",
       "       [0.96521634, 0.        , 0.        , ..., 4.6695347 , 3.2960477 ,\n",
       "        1.622036  ],\n",
       "       [2.0225873 , 0.        , 0.        , ..., 4.669593  , 2.5942886 ,\n",
       "        0.8990636 ],\n",
       "       ...,\n",
       "       [0.904325  , 1.1648356 , 0.        , ..., 5.157652  , 2.6024854 ,\n",
       "        0.55108345],\n",
       "       [1.0081192 , 0.        , 0.        , ..., 4.7771883 , 2.3853168 ,\n",
       "        1.2001423 ],\n",
       "       [1.2436713 , 0.        , 0.        , ..., 4.704373  , 2.9497426 ,\n",
       "        1.4565426 ]], shape=(31854, 2000), dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_real.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.7051982 , 0.91662085, 0.        , ..., 5.165333  , 2.94496   ,\n",
       "        0.91662085],\n",
       "       [0.96521634, 0.        , 0.        , ..., 4.6695347 , 3.2960477 ,\n",
       "        1.622036  ],\n",
       "       [2.0225873 , 0.        , 0.        , ..., 4.669593  , 2.5942886 ,\n",
       "        0.8990636 ],\n",
       "       ...,\n",
       "       [0.904325  , 1.1648356 , 0.        , ..., 5.157652  , 2.6024854 ,\n",
       "        0.55108345],\n",
       "       [1.0081192 , 0.        , 0.        , ..., 4.7771883 , 2.3853168 ,\n",
       "        1.2001423 ],\n",
       "       [1.2436713 , 0.        , 0.        , ..., 4.704373  , 2.9497426 ,\n",
       "        1.4565426 ]], shape=(31854, 2000), dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_new.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values: 0/63708000 (0.00%)\n",
      "Min value: 0.000000\n",
      "Max value: 6.251856\n",
      "After truncation:\n",
      "Min value: 0.000000\n",
      "Max value: 6.251856\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 检查负值情况\n",
    "neg_mask = hepg2_new.X < 0\n",
    "neg_count = neg_mask.sum()\n",
    "total_elements = hepg2_new.X.size\n",
    "\n",
    "print(f\"Negative values: {neg_count}/{total_elements} ({neg_count/total_elements*100:.2f}%)\")\n",
    "print(f\"Min value: {hepg2_new.X.min():.6f}\")\n",
    "print(f\"Max value: {hepg2_new.X.max():.6f}\")\n",
    "\n",
    "# 方法1：直接截断负值为0（最常用）\n",
    "hepg2_new.X = np.maximum(hepg2_new.X, 0)\n",
    "\n",
    "print(f\"After truncation:\")\n",
    "print(f\"Min value: {hepg2_new.X.min():.6f}\")\n",
    "print(f\"Max value: {hepg2_new.X.max():.6f}\")\n",
    "hepg2_real.write_h5ad('/work/home/cryoem666/xyf/temp/pycharm/Squidiff/Squidiff_reproducibility/data/hepg2_squidiff_ours_full_scale0.5_real.h5ad')   \n",
    "hepg2_new.write_h5ad('/work/home/cryoem666/xyf/temp/pycharm/Squidiff/Squidiff_reproducibility/data/hepg2_squidiff_ours_full_scale0.5_pred.h5ad')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.7051982 , 0.91662085, 0.        , ..., 5.165333  , 2.94496   ,\n",
       "         0.91662085],\n",
       "        [0.96521634, 0.        , 0.        , ..., 4.6695347 , 3.2960477 ,\n",
       "         1.622036  ],\n",
       "        [2.0225873 , 0.        , 0.        , ..., 4.669593  , 2.5942886 ,\n",
       "         0.8990636 ],\n",
       "        ...,\n",
       "        [0.904325  , 1.1648356 , 0.        , ..., 5.157652  , 2.6024854 ,\n",
       "         0.55108345],\n",
       "        [1.0081192 , 0.        , 0.        , ..., 4.7771883 , 2.3853168 ,\n",
       "         1.2001423 ],\n",
       "        [1.2436713 , 0.        , 0.        , ..., 4.704373  , 2.9497426 ,\n",
       "         1.4565426 ]], shape=(31854, 2000), dtype=float32),\n",
       " array([[1.0479224 , 0.58396006, 0.16260432, ..., 4.8067646 , 2.9952588 ,\n",
       "         1.0597457 ],\n",
       "        [0.3928091 , 0.5001398 , 0.13378525, ..., 4.699545  , 3.0342236 ,\n",
       "         1.0674665 ],\n",
       "        [0.44279248, 0.40502602, 0.14908704, ..., 4.6760817 , 2.7671125 ,\n",
       "         1.0901204 ],\n",
       "        ...,\n",
       "        [0.7499684 , 0.51036096, 0.15180391, ..., 4.713362  , 3.0377276 ,\n",
       "         1.2175283 ],\n",
       "        [1.0081192 , 0.        , 0.        , ..., 4.7771883 , 2.3853168 ,\n",
       "         1.2001423 ],\n",
       "        [0.65297765, 0.50076026, 0.22405928, ..., 4.911249  , 3.3695593 ,\n",
       "         1.6104852 ]], shape=(31854, 2000), dtype=float32))"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_real.X, hepg2_new.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_pred.X , hepg2_real.X = hepg2_pred.X.astype(np.float32), hepg2_real.X.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/28337 [00:00<?, ?it/s]/tmp/ipykernel_177920/659472469.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
      "  z_sem_origin = torch.tensor(control).to('cuda'),\n",
      "  0%|          | 8/28337 [00:23<23:15:08,  2.95s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m     total_pred.append(scrna_pred)\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m scrna_pred = \u001b[43msampler\u001b[49m\u001b[43m.\u001b[49m\u001b[43minterp_with_direction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mz_sem_origin\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontrol\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgene_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdirection\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_direction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     17\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m total_pred.append(scrna_pred)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/sample_squidiff_ours.py:194\u001b[39m, in \u001b[36msampler.interp_with_direction\u001b[39m\u001b[34m(self, z_sem_origin, gene_size, direction, scale, add_noise_term)\u001b[39m\n\u001b[32m    191\u001b[39m     z_sem_interp_ = \u001b[38;5;28mself\u001b[39m.sample_around_point(z_sem_interp_, num_samples=z_sem_origin.shape[\u001b[32m0\u001b[39m])\n\u001b[32m    193\u001b[39m z_sem_interp_ = torch.tensor(z_sem_interp_,dtype=torch.float32).to(\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m sample_interp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_sem_origin\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mgene_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m                        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mz_mod\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_sem_interp_\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m    201\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.autoencoder:\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/diffusion.py:638\u001b[39m, in \u001b[36mGaussianDiffusion.ddim_sample_loop\u001b[39m\u001b[34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[39m\n\u001b[32m    632\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    633\u001b[39m \u001b[33;03mGenerate samples from the model using DDIM.\u001b[39;00m\n\u001b[32m    634\u001b[39m \n\u001b[32m    635\u001b[39m \u001b[33;03mSame usage as p_sample_loop().\u001b[39;00m\n\u001b[32m    636\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    637\u001b[39m final = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m638\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mddim_sample_loop_progressive\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    639\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    640\u001b[39m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    641\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    642\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    643\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    644\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m    \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msample\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m final[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/diffusion.py:690\u001b[39m, in \u001b[36mGaussianDiffusion.ddim_sample_loop_progressive\u001b[39m\u001b[34m(self, model, shape, noise, clip_denoised, denoised_fn, cond_fn, model_kwargs, device, progress, eta)\u001b[39m\n\u001b[32m    688\u001b[39m t = th.tensor([i] * shape[\u001b[32m0\u001b[39m], device=device)\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mddim_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m        \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcond_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43meta\u001b[49m\u001b[43m=\u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m out\n\u001b[32m    701\u001b[39m     img = out[\u001b[33m\"\u001b[39m\u001b[33msample\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/diffusion.py:547\u001b[39m, in \u001b[36mGaussianDiffusion.ddim_sample\u001b[39m\u001b[34m(self, model, x, t, clip_denoised, denoised_fn, cond_fn, model_kwargs, eta)\u001b[39m\n\u001b[32m    530\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mddim_sample\u001b[39m(\n\u001b[32m    531\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    532\u001b[39m     model,\n\u001b[32m   (...)\u001b[39m\u001b[32m    539\u001b[39m     eta=\u001b[32m0.0\u001b[39m,\n\u001b[32m    540\u001b[39m ):\n\u001b[32m    541\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    542\u001b[39m \u001b[33;03m    Sample x_{t-1} from the model using DDIM.\u001b[39;00m\n\u001b[32m    543\u001b[39m \n\u001b[32m    544\u001b[39m \u001b[33;03m    Same usage as p_sample().\u001b[39;00m\n\u001b[32m    545\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m547\u001b[39m     out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    548\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    549\u001b[39m \u001b[43m        \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    550\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    551\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclip_denoised\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    552\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdenoised_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    553\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    554\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cond_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    556\u001b[39m         out = \u001b[38;5;28mself\u001b[39m.condition_score(cond_fn, out, x, t, model_kwargs=model_kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/respace.py:91\u001b[39m, in \u001b[36mSpacedDiffusion.p_mean_variance\u001b[39m\u001b[34m(self, model, *args, **kwargs)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mp_mean_variance\u001b[39m(\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mself\u001b[39m, model, *args, **kwargs\n\u001b[32m     90\u001b[39m ):  \u001b[38;5;66;03m# pylint: disable=signature-differs\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mp_mean_variance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wrap_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/diffusion.py:256\u001b[39m, in \u001b[36mGaussianDiffusion.p_mean_variance\u001b[39m\u001b[34m(self, model, x, t, clip_denoised, denoised_fn, model_kwargs)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m#print(t.shape)\u001b[39;00m\n\u001b[32m    254\u001b[39m \u001b[38;5;66;03m#print(x.shape)\u001b[39;00m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m t.shape == (B,)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m model_output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_scale_timesteps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_var_type \u001b[38;5;129;01min\u001b[39;00m [ModelVarType.LEARNED, ModelVarType.LEARNED_RANGE]:\n\u001b[32m    259\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m model_output.shape == (B, C * \u001b[32m2\u001b[39m, *x.shape[\u001b[32m2\u001b[39m:])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/respace.py:130\u001b[39m, in \u001b[36m_WrappedModel.__call__\u001b[39m\u001b[34m(self, x, ts, **kwargs)\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.rescale_timesteps:\n\u001b[32m    128\u001b[39m     new_ts = new_ts.float() * (\u001b[32m1000.0\u001b[39m / \u001b[38;5;28mself\u001b[39m.original_num_steps)\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/MLPModel.py:327\u001b[39m, in \u001b[36mour_MLPModel.forward\u001b[39m\u001b[34m(self, x, timesteps, **model_kwargs)\u001b[39m\n\u001b[32m    323\u001b[39m         z_sem = \u001b[38;5;28mself\u001b[39m.encoder(model_kwargs[\u001b[33m'\u001b[39m\u001b[33mx_start\u001b[39m\u001b[33m'\u001b[39m],perturb_label = model_kwargs[\u001b[33m'\u001b[39m\u001b[33mperturb\u001b[39m\u001b[33m'\u001b[39m],batch = model_kwargs[\u001b[33m'\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m'\u001b[39m],cell_type = model_kwargs[\u001b[33m'\u001b[39m\u001b[33mcell_line\u001b[39m\u001b[33m'\u001b[39m])\n\u001b[32m    325\u001b[39m     h = \u001b[38;5;28mself\u001b[39m.input_layer(x)\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m=\u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_sem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mz_sem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m     h = \u001b[38;5;28mself\u001b[39m.output_layer(h)\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/MLPModel.py:75\u001b[39m, in \u001b[36mTimestepEmbedSequential.forward\u001b[39m\u001b[34m(self, x, emb, z_sem)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m     74\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, TimestepBlock):\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m         x = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz_sem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         x = layer(x)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/xyf/temp/pycharm/Squidiff/Squidiff/MLPModel.py:56\u001b[39m, in \u001b[36mMLPBlock.forward\u001b[39m\u001b[34m(self, x, emb, z_sem)\u001b[39m\n\u001b[32m     54\u001b[39m     h = h + \u001b[38;5;28mself\u001b[39m.time_dense(emb)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m ((emb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)&(z_sem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)):\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     h = h + \u001b[38;5;28mself\u001b[39m.time_dense(emb)+\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mzsem_dense\u001b[49m(z_sem)\n\u001b[32m     57\u001b[39m h = F.silu(\u001b[38;5;28mself\u001b[39m.layer_norm2(\u001b[38;5;28mself\u001b[39m.fc2(h)))\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/torch/nn/modules/module.py:1915\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1912\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1913\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1914\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1915\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1916\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1917\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "control = [direction_dict[('non-targeting','hepg2')]]\n",
    "total_pred = []\n",
    "for  in tqdm(range(hepg2_real.n_obs)): \n",
    "    x_i, obs_i = hepg2_real.X[i], hepg2_real.obs.iloc[i]\n",
    "    perturb, cell_type = obs_i['gene'], obs_i['cell_type']\n",
    "    new_direction = avg_direction[perturb]\n",
    "    if perturb == 'non-targeting':\n",
    "        scrna_pred = x_i\n",
    "        total_pred.append(scrna_pred)\n",
    "        continue\n",
    "    scrna_pred = sampler.interp_with_direction(\n",
    "        z_sem_origin = torch.tensor(control).to('cuda'),\n",
    "        gene_size = 128,\n",
    "        direction = torch.tensor(new_direction).to('cuda'),\n",
    "        scale = 1\n",
    "    )\n",
    "    total_pred.append(scrna_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "hepg2_pred_squidiff_ours = hepg2_real.copy()\n",
    "hepg2_pred_squidiff_ours.X = np.array(total_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_123690/983445336.py:4: ImplicitModificationWarning: Setting element `.obsm['VAE_latent']` of view, initializing view as actual.\n",
      "  case.obsm['VAE_latent'] = sampler.autoencoder(torch.tensor(case[:, case.var['highly_variable']].X.toarray()).to('cuda'), return_latent=True).detach().cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "case = state_Data[(state_Data.obs['gene']==perturb_list[0]) & (state_Data.obs['cell_line']=='hepg2')]\n",
    "case.obsm['VAE_latent'] = sampler.autoencoder(torch.tensor(case[:, case.var['highly_variable']].X.toarray()).to('cuda'), return_latent=True).detach().cpu().numpy()\n",
    "z_sem = sampler.model.encoder.forward(\n",
    "    torch.tensor(case.obsm['VAE_latent']).to('cuda'),\n",
    "    cell_type = torch.tensor(np.stack(case.obs['cell_line_label'].values), dtype=torch.int32).to('cuda'),\n",
    "    batch = torch.tensor(np.stack(case.obs['batch_label'].values), dtype=torch.int32).to('cuda'),\n",
    "    perturb_label = torch.tensor(np.stack(case.obs['perturb_label'].values), dtype=torch.int32).to('cuda'),\n",
    ")\n",
    "\n",
    "scrnas_pred = sampler.pred(z_sem, 128)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = case[:, case.var['highly_variable']].X, scrnas_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/data/state_original_hf_hepg2/adata_pred.h5ad')\n",
    "hepg2_real = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/data/state_original_hf_hepg2/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "hepg2_pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/cpa_replogle_v2/fold1/adata_pred.h5ad')\n",
    "hepg2_real = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/cpa_replogle_v2/fold1/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrlm_pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/lrlm_replogle_v2/fold1/adata_pred.h5ad')\n",
    "lrlm_real = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state-reproduce/baselines/baseline_output/lrlm_replogle_v2/fold1/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hepg2_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mhepg2_pred\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'hepg2_pred' is not defined"
     ]
    }
   ],
   "source": [
    "mmd_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Boolean index does not match AnnData’s shape along this dimension. Boolean index has shape (31854,) while AnnData index has shape (31545,).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[107]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m mmd_dict_lrlm = {}\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m perturb \u001b[38;5;129;01min\u001b[39;00m perturb_list:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     mmd_dict_lrlm[perturb] = mmd_loss(\u001b[43mlrlm_real\u001b[49m\u001b[43m[\u001b[49m\u001b[43mscvi_real\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpert_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m==\u001b[49m\u001b[43mperturb\u001b[49m\u001b[43m]\u001b[49m.X.toarray(), lrlm_pred[lrlm_pred.obs[\u001b[33m'\u001b[39m\u001b[33mpert_name\u001b[39m\u001b[33m'\u001b[39m]==perturb].X.toarray())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/anndata/_core/anndata.py:1058\u001b[39m, in \u001b[36mAnnData.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: Index) -> AnnData:\n\u001b[32m   1057\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns a sliced view of the object.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1058\u001b[39m     oidx, vidx = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_normalize_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1059\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m AnnData(\u001b[38;5;28mself\u001b[39m, oidx=oidx, vidx=vidx, asview=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/anndata/_core/anndata.py:1039\u001b[39m, in \u001b[36mAnnData._normalize_indices\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m   1036\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_normalize_indices\u001b[39m(\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28mself\u001b[39m, index: Index | \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1038\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Index1DNorm | \u001b[38;5;28mint\u001b[39m | np.integer, Index1DNorm | \u001b[38;5;28mint\u001b[39m | np.integer]:\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_normalize_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobs_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/anndata/_core/index.py:35\u001b[39m, in \u001b[36m_normalize_indices\u001b[39m\u001b[34m(index, names0, names1)\u001b[39m\n\u001b[32m     33\u001b[39m     index = \u001b[38;5;28mtuple\u001b[39m(i.values \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(i, pd.Series) \u001b[38;5;28;01melse\u001b[39;00m i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m index)\n\u001b[32m     34\u001b[39m ax0, ax1 = unpack_index(index)\n\u001b[32m---> \u001b[39m\u001b[32m35\u001b[39m ax0 = \u001b[43m_normalize_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43max0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m ax1 = _normalize_index(ax1, names1)\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ax0, ax1\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/my_state/lib/python3.12/site-packages/anndata/_core/index.py:97\u001b[39m, in \u001b[36m_normalize_index\u001b[39m\u001b[34m(indexer, index)\u001b[39m\n\u001b[32m     91\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m indexer.shape != index.shape:\n\u001b[32m     92\u001b[39m         msg = (\n\u001b[32m     93\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBoolean index does not match AnnData’s shape along this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdimension. Boolean index has shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindexer.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m while \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnnData index has shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m         )\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(msg)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# indexer should be string array\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: Boolean index does not match AnnData’s shape along this dimension. Boolean index has shape (31854,) while AnnData index has shape (31545,)."
     ]
    }
   ],
   "source": [
    "mmd_dict_lrlm = {}\n",
    "for perturb in perturb_list:\n",
    "    mmd_dict_lrlm[perturb] = mmd_loss(lrlm_real[scvi_real.obs['pert_name']==perturb].X.toarray(), lrlm_pred[lrlm_pred.obs['pert_name']==perturb].X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dict_scvi = {}\n",
    "for perturb in perturb_list:\n",
    "    mmd_dict_scvi[perturb] = mmd_loss(scvi_real[scvi_real.obs['pert_name']==perturb].X.toarray(), scvi_pred[scvi_pred.obs['pert_name']==perturb].X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([tensor(1.1719, device='cuda:0'), tensor(1.2397, device='cuda:0'), tensor(1.1240, device='cuda:0'), tensor(1.1201, device='cuda:0'), tensor(1.1806, device='cuda:0'), tensor(1.2235, device='cuda:0'), tensor(1.2302, device='cuda:0'), tensor(1.2562, device='cuda:0'), tensor(1.2109, device='cuda:0'), tensor(1.2344, device='cuda:0'), tensor(1.3507, device='cuda:0'), tensor(1.1334, device='cuda:0'), tensor(1.2518, device='cuda:0'), tensor(1.2789, device='cuda:0'), tensor(1.2349, device='cuda:0'), tensor(1.1931, device='cuda:0'), tensor(1.1786, device='cuda:0'), tensor(1.1908, device='cuda:0'), tensor(1.2136, device='cuda:0'), tensor(1.2522, device='cuda:0'), tensor(1.2078, device='cuda:0'), tensor(1.2285, device='cuda:0'), tensor(1.2760, device='cuda:0'), tensor(1.1847, device='cuda:0'), tensor(1.1848, device='cuda:0'), tensor(1.1619, device='cuda:0'), tensor(1.1951, device='cuda:0'), tensor(1.2461, device='cuda:0'), tensor(1.1277, device='cuda:0'), tensor(1.2273, device='cuda:0'), tensor(1.3204, device='cuda:0'), tensor(1.1233, device='cuda:0'), tensor(1.2377, device='cuda:0'), tensor(1.1176, device='cuda:0'), tensor(1.2562, device='cuda:0'), tensor(1.1967, device='cuda:0'), tensor(1.1356, device='cuda:0'), tensor(1.2323, device='cuda:0'), tensor(1.3721, device='cuda:0'), tensor(1.1411, device='cuda:0'), tensor(1.0539, device='cuda:0'), tensor(1.2166, device='cuda:0'), tensor(1.1395, device='cuda:0'), tensor(1.1810, device='cuda:0'), tensor(1.1382, device='cuda:0'), tensor(1.1305, device='cuda:0'), tensor(1.4862, device='cuda:0'), tensor(1.1251, device='cuda:0'), tensor(1.3062, device='cuda:0'), tensor(1.1964, device='cuda:0'), tensor(1.2048, device='cuda:0'), tensor(1.2146, device='cuda:0'), tensor(1.1052, device='cuda:0'), tensor(1.2129, device='cuda:0'), tensor(1.1974, device='cuda:0'), tensor(1.2996, device='cuda:0'), tensor(1.1373, device='cuda:0'), tensor(1.1733, device='cuda:0'), tensor(1.1941, device='cuda:0'), tensor(1.2105, device='cuda:0'), tensor(1.2719, device='cuda:0'), tensor(1.1838, device='cuda:0'), tensor(1.4877, device='cuda:0'), tensor(1.2063, device='cuda:0'), tensor(1.0573, device='cuda:0'), tensor(1.1829, device='cuda:0'), tensor(1.2949, device='cuda:0'), tensor(1.5674, device='cuda:0'), tensor(1.2841, device='cuda:0'), tensor(1.1832, device='cuda:0'), tensor(1.2251, device='cuda:0'), tensor(1.2745, device='cuda:0'), tensor(1.1599, device='cuda:0'), tensor(1.1985, device='cuda:0'), tensor(1.2166, device='cuda:0'), tensor(1.2129, device='cuda:0'), tensor(1.3142, device='cuda:0'), tensor(1.1277, device='cuda:0'), tensor(1.2559, device='cuda:0'), tensor(1.1779, device='cuda:0'), tensor(1.2894, device='cuda:0'), tensor(1.3574, device='cuda:0'), tensor(1.2306, device='cuda:0'), tensor(1.3235, device='cuda:0'), tensor(1.1813, device='cuda:0'), tensor(1.2877, device='cuda:0'), tensor(1.1916, device='cuda:0'), tensor(1.2068, device='cuda:0'), tensor(1.2091, device='cuda:0'), tensor(1.2291, device='cuda:0'), tensor(1.0826, device='cuda:0'), tensor(1.1457, device='cuda:0'), tensor(1.1776, device='cuda:0'), tensor(1.2664, device='cuda:0'), tensor(1.1400, device='cuda:0'), tensor(1.1864, device='cuda:0'), tensor(1.3200, device='cuda:0'), tensor(1.1909, device='cuda:0'), tensor(1.0879, device='cuda:0'), tensor(1.2157, device='cuda:0'), tensor(1.3462, device='cuda:0'), tensor(1.1872, device='cuda:0'), tensor(1.1429, device='cuda:0'), tensor(1.3551, device='cuda:0'), tensor(1.2571, device='cuda:0'), tensor(1.1326, device='cuda:0'), tensor(1.1691, device='cuda:0'), tensor(1.1689, device='cuda:0'), tensor(1.2737, device='cuda:0'), tensor(1.1305, device='cuda:0'), tensor(1.2905, device='cuda:0'), tensor(1.3077, device='cuda:0'), tensor(1.4033, device='cuda:0'), tensor(1.3033, device='cuda:0'), tensor(1.2752, device='cuda:0'), tensor(1.3461, device='cuda:0'), tensor(1.3231, device='cuda:0'), tensor(1.2835, device='cuda:0'), tensor(1.1750, device='cuda:0'), tensor(1.1130, device='cuda:0'), tensor(1.1878, device='cuda:0'), tensor(1.1638, device='cuda:0'), tensor(1.3681, device='cuda:0'), tensor(1.1359, device='cuda:0'), tensor(1.1884, device='cuda:0'), tensor(1.4182, device='cuda:0'), tensor(1.0711, device='cuda:0'), tensor(1.2524, device='cuda:0'), tensor(1.1880, device='cuda:0'), tensor(1.0929, device='cuda:0'), tensor(1.2147, device='cuda:0'), tensor(1.3020, device='cuda:0'), tensor(1.2455, device='cuda:0'), tensor(1.1585, device='cuda:0'), tensor(1.1259, device='cuda:0'), tensor(1.3511, device='cuda:0'), tensor(1.1738, device='cuda:0'), tensor(1.1080, device='cuda:0'), tensor(1.2186, device='cuda:0'), tensor(1.1365, device='cuda:0'), tensor(1.3093, device='cuda:0'), tensor(1.3260, device='cuda:0'), tensor(1.2344, device='cuda:0'), tensor(1.1699, device='cuda:0'), tensor(1.2174, device='cuda:0'), tensor(1.2043, device='cuda:0'), tensor(1.1817, device='cuda:0'), tensor(1.2929, device='cuda:0'), tensor(1.2117, device='cuda:0'), tensor(1.1669, device='cuda:0'), tensor(1.1653, device='cuda:0'), tensor(1.1915, device='cuda:0'), tensor(1.2782, device='cuda:0'), tensor(1.2565, device='cuda:0'), tensor(1.0975, device='cuda:0'), tensor(1.2343, device='cuda:0'), tensor(1.2199, device='cuda:0'), tensor(1.2095, device='cuda:0'), tensor(1.3685, device='cuda:0'), tensor(1.1257, device='cuda:0'), tensor(1.1649, device='cuda:0'), tensor(1.2505, device='cuda:0'), tensor(1.2383, device='cuda:0'), tensor(1.1630, device='cuda:0'), tensor(1.2492, device='cuda:0'), tensor(1.1457, device='cuda:0'), tensor(1.2812, device='cuda:0'), tensor(1.2380, device='cuda:0'), tensor(1.2226, device='cuda:0'), tensor(1.2558, device='cuda:0'), tensor(1.1352, device='cuda:0'), tensor(1.1785, device='cuda:0'), tensor(1.1261, device='cuda:0'), tensor(2.0361, device='cuda:0'), tensor(1.1858, device='cuda:0'), tensor(1.2095, device='cuda:0'), tensor(1.2120, device='cuda:0'), tensor(1.1174, device='cuda:0'), tensor(1.1762, device='cuda:0'), tensor(1.2617, device='cuda:0'), tensor(1.1183, device='cuda:0'), tensor(1.2542, device='cuda:0'), tensor(1.3951, device='cuda:0'), tensor(1.1581, device='cuda:0'), tensor(1.3849, device='cuda:0'), tensor(1.1583, device='cuda:0'), tensor(1.1756, device='cuda:0'), tensor(1.1450, device='cuda:0'), tensor(1.2578, device='cuda:0'), tensor(1.1360, device='cuda:0'), tensor(1.1095, device='cuda:0'), tensor(1.2715, device='cuda:0'), tensor(1.2196, device='cuda:0'), tensor(1.1427, device='cuda:0'), tensor(1.2409, device='cuda:0'), tensor(1.1314, device='cuda:0'), tensor(1.2313, device='cuda:0'), tensor(1.4928, device='cuda:0'), tensor(1.2923, device='cuda:0'), tensor(1.0334, device='cuda:0'), tensor(1.1613, device='cuda:0'), tensor(1.2058, device='cuda:0'), tensor(1.1967, device='cuda:0'), tensor(1.2522, device='cuda:0'), tensor(1.2028, device='cuda:0'), tensor(1.2083, device='cuda:0'), tensor(1.2893, device='cuda:0'), tensor(1.2260, device='cuda:0'), tensor(1.1737, device='cuda:0'), tensor(1.2313, device='cuda:0'), tensor(1.2480, device='cuda:0'), tensor(1.1704, device='cuda:0'), tensor(1.1770, device='cuda:0'), tensor(1.2443, device='cuda:0'), tensor(1.2100, device='cuda:0'), tensor(1.2387, device='cuda:0'), tensor(1.1967, device='cuda:0'), tensor(1.1952, device='cuda:0'), tensor(1.1728, device='cuda:0'), tensor(1.2079, device='cuda:0'), tensor(1.2980, device='cuda:0'), tensor(1.1319, device='cuda:0'), tensor(1.1421, device='cuda:0'), tensor(1.1392, device='cuda:0'), tensor(1.2219, device='cuda:0'), tensor(1.1524, device='cuda:0'), tensor(1.1721, device='cuda:0'), tensor(1.1091, device='cuda:0'), tensor(1.1059, device='cuda:0'), tensor(1.1977, device='cuda:0'), tensor(1.1327, device='cuda:0'), tensor(1.3345, device='cuda:0'), tensor(1.0822, device='cuda:0'), tensor(1.2580, device='cuda:0'), tensor(1.1222, device='cuda:0'), tensor(1.2141, device='cuda:0'), tensor(1.3158, device='cuda:0'), tensor(1.2538, device='cuda:0'), tensor(1.1946, device='cuda:0'), tensor(1.1976, device='cuda:0'), tensor(1.1996, device='cuda:0'), tensor(1.1856, device='cuda:0'), tensor(1.2796, device='cuda:0'), tensor(1.1848, device='cuda:0'), tensor(1.1550, device='cuda:0'), tensor(1.2176, device='cuda:0'), tensor(1.2525, device='cuda:0'), tensor(1.1269, device='cuda:0'), tensor(1.1202, device='cuda:0'), tensor(1.2048, device='cuda:0'), tensor(1.1680, device='cuda:0'), tensor(1.1981, device='cuda:0'), tensor(1.1375, device='cuda:0'), tensor(1.4326, device='cuda:0'), tensor(1.2349, device='cuda:0'), tensor(1.1549, device='cuda:0'), tensor(1.1731, device='cuda:0'), tensor(1.3801, device='cuda:0'), tensor(1.1461, device='cuda:0'), tensor(1.1765, device='cuda:0'), tensor(1.1852, device='cuda:0'), tensor(1.1838, device='cuda:0'), tensor(1.1792, device='cuda:0'), tensor(1.1398, device='cuda:0'), tensor(1.1117, device='cuda:0'), tensor(1.1080, device='cuda:0'), tensor(1.1149, device='cuda:0'), tensor(1.1678, device='cuda:0'), tensor(1.1532, device='cuda:0'), tensor(1.2219, device='cuda:0'), tensor(1.2809, device='cuda:0'), tensor(1.1103, device='cuda:0'), tensor(1.2146, device='cuda:0'), tensor(1.1527, device='cuda:0'), tensor(1.1870, device='cuda:0'), tensor(1.2463, device='cuda:0'), tensor(1.2011, device='cuda:0'), tensor(1.2950, device='cuda:0'), tensor(1.1296, device='cuda:0'), tensor(1.2310, device='cuda:0'), tensor(1.1957, device='cuda:0'), tensor(1.1134, device='cuda:0'), tensor(1.1832, device='cuda:0'), tensor(1.1885, device='cuda:0'), tensor(1.2453, device='cuda:0'), tensor(1.2164, device='cuda:0'), tensor(1.4074, device='cuda:0'), tensor(1.4478, device='cuda:0'), tensor(1.2356, device='cuda:0'), tensor(1.1478, device='cuda:0'), tensor(1.2007, device='cuda:0'), tensor(1.1198, device='cuda:0'), tensor(1.1612, device='cuda:0'), tensor(1.1251, device='cuda:0'), tensor(1.2557, device='cuda:0'), tensor(1.1953, device='cuda:0'), tensor(1.3194, device='cuda:0'), tensor(1.3432, device='cuda:0'), tensor(1.2232, device='cuda:0'), tensor(1.3320, device='cuda:0'), tensor(1.1999, device='cuda:0'), tensor(1.2488, device='cuda:0'), tensor(1.2439, device='cuda:0'), tensor(1.0799, device='cuda:0'), tensor(1.2094, device='cuda:0'), tensor(1.2757, device='cuda:0'), tensor(1.2306, device='cuda:0'), tensor(1.0939, device='cuda:0'), tensor(1.1795, device='cuda:0'), tensor(1.2306, device='cuda:0'), tensor(1.1817, device='cuda:0'), tensor(1.2311, device='cuda:0'), tensor(1.1834, device='cuda:0'), tensor(1.2160, device='cuda:0'), tensor(1.1275, device='cuda:0'), tensor(1.1144, device='cuda:0'), tensor(1.1038, device='cuda:0'), tensor(1.1838, device='cuda:0'), tensor(1.1382, device='cuda:0'), tensor(1.2377, device='cuda:0'), tensor(1.1220, device='cuda:0'), tensor(1.1131, device='cuda:0'), tensor(1.1696, device='cuda:0'), tensor(1.2847, device='cuda:0'), tensor(1.1320, device='cuda:0'), tensor(1.2064, device='cuda:0'), tensor(1.2426, device='cuda:0'), tensor(1.2101, device='cuda:0'), tensor(1.1291, device='cuda:0'), tensor(1.1951, device='cuda:0'), tensor(1.2019, device='cuda:0'), tensor(1.1138, device='cuda:0'), tensor(1.3128, device='cuda:0'), tensor(1.1704, device='cuda:0'), tensor(1.2144, device='cuda:0'), tensor(1.0959, device='cuda:0'), tensor(1.1476, device='cuda:0'), tensor(1.2535, device='cuda:0'), tensor(1.3951, device='cuda:0'), tensor(1.2623, device='cuda:0'), tensor(1.1710, device='cuda:0'), tensor(1.1948, device='cuda:0'), tensor(1.1206, device='cuda:0'), tensor(1.1571, device='cuda:0'), tensor(1.2665, device='cuda:0'), tensor(1.2441, device='cuda:0'), tensor(1.3077, device='cuda:0'), tensor(1.2629, device='cuda:0'), tensor(1.1297, device='cuda:0'), tensor(1.1509, device='cuda:0'), tensor(1.2600, device='cuda:0'), tensor(1.1408, device='cuda:0'), tensor(1.6357, device='cuda:0'), tensor(1.2049, device='cuda:0'), tensor(1.1200, device='cuda:0'), tensor(1.1837, device='cuda:0'), tensor(1.2780, device='cuda:0'), tensor(1.2036, device='cuda:0'), tensor(1.3507, device='cuda:0'), tensor(1.2458, device='cuda:0'), tensor(1.1438, device='cuda:0'), tensor(1.2393, device='cuda:0'), tensor(1.6642, device='cuda:0'), tensor(1.1946, device='cuda:0'), tensor(1.2410, device='cuda:0'), tensor(1.3752, device='cuda:0'), tensor(1.2555, device='cuda:0'), tensor(1.3225, device='cuda:0'), tensor(1.1181, device='cuda:0'), tensor(1.1962, device='cuda:0'), tensor(1.1191, device='cuda:0'), tensor(1.1920, device='cuda:0'), tensor(1.3226, device='cuda:0'), tensor(1.3454, device='cuda:0'), tensor(1.4596, device='cuda:0'), tensor(1.1008, device='cuda:0'), tensor(1.1102, device='cuda:0'), tensor(1.0988, device='cuda:0'), tensor(1.1508, device='cuda:0'), tensor(1.1377, device='cuda:0'), tensor(1.2137, device='cuda:0')])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_dict_scvi.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmd_dict = {}\n",
    "for perturb in perturb_list:\n",
    "    mmd_dict[perturb] = mmd_loss(hepg2_real[hepg2_real.obs['gene']==perturb].X.toarray(), hepg2_pred[hepg2_pred.obs['gene']==perturb].X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UROD': tensor(1.1719, device='cuda:0'),\n",
       " 'GFER': tensor(1.2397, device='cuda:0'),\n",
       " 'MED8': tensor(1.1240, device='cuda:0'),\n",
       " 'C9orf16': tensor(1.1201, device='cuda:0'),\n",
       " 'HNRNPDL': tensor(1.1806, device='cuda:0'),\n",
       " 'CCP110': tensor(1.2235, device='cuda:0'),\n",
       " 'TRMT112': tensor(1.2302, device='cuda:0'),\n",
       " 'TSFM': tensor(1.2562, device='cuda:0'),\n",
       " 'NUDC': tensor(1.2109, device='cuda:0'),\n",
       " 'SMNDC1': tensor(1.2344, device='cuda:0'),\n",
       " 'AGBL5': tensor(1.3507, device='cuda:0'),\n",
       " 'CCDC6': tensor(1.1334, device='cuda:0'),\n",
       " 'SOD2': tensor(1.2518, device='cuda:0'),\n",
       " 'NELFE': tensor(1.2789, device='cuda:0'),\n",
       " 'COG2': tensor(1.2349, device='cuda:0'),\n",
       " 'CYFIP1': tensor(1.1931, device='cuda:0'),\n",
       " 'SDHC': tensor(1.1786, device='cuda:0'),\n",
       " 'C19orf53': tensor(1.1908, device='cuda:0'),\n",
       " 'MSL1': tensor(1.2136, device='cuda:0'),\n",
       " 'PPIL2': tensor(1.2522, device='cuda:0'),\n",
       " 'CLPB': tensor(1.2078, device='cuda:0'),\n",
       " 'BCLAF1': tensor(1.2285, device='cuda:0'),\n",
       " 'COPS2': tensor(1.2760, device='cuda:0'),\n",
       " 'RPP14': tensor(1.1847, device='cuda:0'),\n",
       " 'ANKRD49': tensor(1.1848, device='cuda:0'),\n",
       " 'BAG6': tensor(1.1619, device='cuda:0'),\n",
       " 'ISG20L2': tensor(1.1951, device='cuda:0'),\n",
       " 'CWC15': tensor(1.2461, device='cuda:0'),\n",
       " 'NCAPD2': tensor(1.1277, device='cuda:0'),\n",
       " 'NUP88': tensor(1.2273, device='cuda:0'),\n",
       " 'ARGLU1': tensor(1.3204, device='cuda:0'),\n",
       " 'C7orf26': tensor(1.1233, device='cuda:0'),\n",
       " 'CPSF6': tensor(1.2377, device='cuda:0'),\n",
       " 'PLK4': tensor(1.1176, device='cuda:0'),\n",
       " 'RAB6A': tensor(1.2562, device='cuda:0'),\n",
       " 'RPL29': tensor(1.1967, device='cuda:0'),\n",
       " 'MED14': tensor(1.1356, device='cuda:0'),\n",
       " 'KIF18B': tensor(1.2323, device='cuda:0'),\n",
       " 'UBAP1': tensor(1.3721, device='cuda:0'),\n",
       " 'NELFA': tensor(1.1411, device='cuda:0'),\n",
       " 'RNGTT': tensor(1.0539, device='cuda:0'),\n",
       " 'GART': tensor(1.2166, device='cuda:0'),\n",
       " 'CPSF3': tensor(1.1395, device='cuda:0'),\n",
       " 'LAS1L': tensor(1.1810, device='cuda:0'),\n",
       " 'VPS29': tensor(1.1382, device='cuda:0'),\n",
       " 'TRA2B': tensor(1.1305, device='cuda:0'),\n",
       " 'EIF2S1': tensor(1.4862, device='cuda:0'),\n",
       " 'NIFK': tensor(1.1251, device='cuda:0'),\n",
       " 'GLE1': tensor(1.3062, device='cuda:0'),\n",
       " 'USP10': tensor(1.1964, device='cuda:0'),\n",
       " 'RFC2': tensor(1.2048, device='cuda:0'),\n",
       " 'CCT7': tensor(1.2146, device='cuda:0'),\n",
       " 'MRPL3': tensor(1.1052, device='cuda:0'),\n",
       " 'CDC6': tensor(1.2129, device='cuda:0'),\n",
       " 'UTP15': tensor(1.1974, device='cuda:0'),\n",
       " 'RPS21': tensor(1.2996, device='cuda:0'),\n",
       " 'BRCA2': tensor(1.1373, device='cuda:0'),\n",
       " 'XPO5': tensor(1.1733, device='cuda:0'),\n",
       " 'GTF2H4': tensor(1.1941, device='cuda:0'),\n",
       " 'ACTR1B': tensor(1.2105, device='cuda:0'),\n",
       " 'SEC61G': tensor(1.2719, device='cuda:0'),\n",
       " 'NOL7': tensor(1.1838, device='cuda:0'),\n",
       " 'LARS': tensor(1.4877, device='cuda:0'),\n",
       " 'WARS': tensor(1.2063, device='cuda:0'),\n",
       " 'RRP15': tensor(1.0573, device='cuda:0'),\n",
       " 'RBMXL1': tensor(1.1829, device='cuda:0'),\n",
       " 'NUTF2': tensor(1.2949, device='cuda:0'),\n",
       " 'RPS2': tensor(1.5674, device='cuda:0'),\n",
       " 'IST1': tensor(1.2841, device='cuda:0'),\n",
       " 'MIS18BP1': tensor(1.1832, device='cuda:0'),\n",
       " 'WBP1': tensor(1.2251, device='cuda:0'),\n",
       " 'PTMA': tensor(1.2745, device='cuda:0'),\n",
       " 'NHLRC2': tensor(1.1599, device='cuda:0'),\n",
       " 'VARS2': tensor(1.1985, device='cuda:0'),\n",
       " 'YARS2': tensor(1.2166, device='cuda:0'),\n",
       " 'COMTD1': tensor(1.2129, device='cuda:0'),\n",
       " 'NOL11': tensor(1.3142, device='cuda:0'),\n",
       " 'USP14': tensor(1.1277, device='cuda:0'),\n",
       " 'EFR3A': tensor(1.2559, device='cuda:0'),\n",
       " 'GPS1': tensor(1.1779, device='cuda:0'),\n",
       " 'CACTIN': tensor(1.2894, device='cuda:0'),\n",
       " 'RUVBL2': tensor(1.3574, device='cuda:0'),\n",
       " 'MED9': tensor(1.2306, device='cuda:0'),\n",
       " 'PAF1': tensor(1.3235, device='cuda:0'),\n",
       " 'SART3': tensor(1.1813, device='cuda:0'),\n",
       " 'MYBBP1A': tensor(1.2877, device='cuda:0'),\n",
       " 'SLU7': tensor(1.1916, device='cuda:0'),\n",
       " 'NOL6': tensor(1.2068, device='cuda:0'),\n",
       " 'RPS28': tensor(1.2091, device='cuda:0'),\n",
       " 'FNTA': tensor(1.2291, device='cuda:0'),\n",
       " 'SRP14': tensor(1.0826, device='cuda:0'),\n",
       " 'PRPF39': tensor(1.1457, device='cuda:0'),\n",
       " 'LAMB1': tensor(1.1776, device='cuda:0'),\n",
       " 'MVD': tensor(1.2664, device='cuda:0'),\n",
       " 'MEN1': tensor(1.1400, device='cuda:0'),\n",
       " 'TFB1M': tensor(1.1864, device='cuda:0'),\n",
       " 'BYSL': tensor(1.3200, device='cuda:0'),\n",
       " 'RBM42': tensor(1.1909, device='cuda:0'),\n",
       " 'MRPL35': tensor(1.0879, device='cuda:0'),\n",
       " 'FAU': tensor(1.2157, device='cuda:0'),\n",
       " 'DHX16': tensor(1.3462, device='cuda:0'),\n",
       " 'COG6': tensor(1.1872, device='cuda:0'),\n",
       " 'MAT2A': tensor(1.1429, device='cuda:0'),\n",
       " 'NDUFB4': tensor(1.3551, device='cuda:0'),\n",
       " 'MRPS23': tensor(1.2571, device='cuda:0'),\n",
       " 'PMF1': tensor(1.1326, device='cuda:0'),\n",
       " 'MED19': tensor(1.1691, device='cuda:0'),\n",
       " 'CCDC59': tensor(1.1689, device='cuda:0'),\n",
       " 'MED21': tensor(1.2737, device='cuda:0'),\n",
       " 'MVK': tensor(1.1305, device='cuda:0'),\n",
       " 'ERAL1': tensor(1.2905, device='cuda:0'),\n",
       " 'CPSF1': tensor(1.3077, device='cuda:0'),\n",
       " 'DDX18': tensor(1.4033, device='cuda:0'),\n",
       " 'IARS2': tensor(1.3033, device='cuda:0'),\n",
       " 'GINS2': tensor(1.2752, device='cuda:0'),\n",
       " 'RARS': tensor(1.3461, device='cuda:0'),\n",
       " 'POLR1E': tensor(1.3231, device='cuda:0'),\n",
       " 'CDC20': tensor(1.2835, device='cuda:0'),\n",
       " 'SPAG7': tensor(1.1750, device='cuda:0'),\n",
       " 'TUBE1': tensor(1.1130, device='cuda:0'),\n",
       " 'DDX52': tensor(1.1878, device='cuda:0'),\n",
       " 'SMC5': tensor(1.1638, device='cuda:0'),\n",
       " 'UTP11': tensor(1.3681, device='cuda:0'),\n",
       " 'DIMT1': tensor(1.1359, device='cuda:0'),\n",
       " 'CHCHD4': tensor(1.1884, device='cuda:0'),\n",
       " 'RPL7': tensor(1.4182, device='cuda:0'),\n",
       " 'TP53I13': tensor(1.0711, device='cuda:0'),\n",
       " 'PRELID3B': tensor(1.2524, device='cuda:0'),\n",
       " 'SRP72': tensor(1.1880, device='cuda:0'),\n",
       " 'VPS54': tensor(1.0929, device='cuda:0'),\n",
       " 'RNPC3': tensor(1.2147, device='cuda:0'),\n",
       " 'STRIP1': tensor(1.3020, device='cuda:0'),\n",
       " 'KAT7': tensor(1.2455, device='cuda:0'),\n",
       " 'SNRNP27': tensor(1.1585, device='cuda:0'),\n",
       " 'PIAS1': tensor(1.1259, device='cuda:0'),\n",
       " 'MRM1': tensor(1.3511, device='cuda:0'),\n",
       " 'RPP21': tensor(1.1738, device='cuda:0'),\n",
       " 'PPP6C': tensor(1.1080, device='cuda:0'),\n",
       " 'COG4': tensor(1.2186, device='cuda:0'),\n",
       " 'RPIA': tensor(1.1365, device='cuda:0'),\n",
       " 'NBAS': tensor(1.3093, device='cuda:0'),\n",
       " 'VPS13D': tensor(1.3260, device='cuda:0'),\n",
       " 'ZNHIT6': tensor(1.2344, device='cuda:0'),\n",
       " 'ACTR8': tensor(1.1699, device='cuda:0'),\n",
       " 'TFRC': tensor(1.2174, device='cuda:0'),\n",
       " 'RPAP2': tensor(1.2043, device='cuda:0'),\n",
       " 'ZNF787': tensor(1.1817, device='cuda:0'),\n",
       " 'BARD1': tensor(1.2929, device='cuda:0'),\n",
       " 'OPA1': tensor(1.2117, device='cuda:0'),\n",
       " 'YPEL5': tensor(1.1669, device='cuda:0'),\n",
       " 'MASTL': tensor(1.1653, device='cuda:0'),\n",
       " 'POP1': tensor(1.1915, device='cuda:0'),\n",
       " 'FAM32A': tensor(1.2782, device='cuda:0'),\n",
       " 'PAXBP1': tensor(1.2565, device='cuda:0'),\n",
       " 'OSTC': tensor(1.0975, device='cuda:0'),\n",
       " 'SRRM2': tensor(1.2343, device='cuda:0'),\n",
       " 'TTC4': tensor(1.2199, device='cuda:0'),\n",
       " 'DENR': tensor(1.2095, device='cuda:0'),\n",
       " 'ZC3H13': tensor(1.3685, device='cuda:0'),\n",
       " 'MRPS16': tensor(1.1257, device='cuda:0'),\n",
       " 'HSP90B1': tensor(1.1649, device='cuda:0'),\n",
       " 'TPRKB': tensor(1.2505, device='cuda:0'),\n",
       " 'TM7SF2': tensor(1.2383, device='cuda:0'),\n",
       " 'KDM1A': tensor(1.1630, device='cuda:0'),\n",
       " 'MDN1': tensor(1.2492, device='cuda:0'),\n",
       " 'TMX2': tensor(1.1457, device='cuda:0'),\n",
       " 'EIF1AX': tensor(1.2812, device='cuda:0'),\n",
       " 'TAF10': tensor(1.2380, device='cuda:0'),\n",
       " 'INTS12': tensor(1.2226, device='cuda:0'),\n",
       " 'INTS6': tensor(1.2558, device='cuda:0'),\n",
       " 'AIFM1': tensor(1.1352, device='cuda:0'),\n",
       " 'ANAPC13': tensor(1.1785, device='cuda:0'),\n",
       " 'SAMD4B': tensor(1.1261, device='cuda:0'),\n",
       " 'RPS20': tensor(2.0361, device='cuda:0'),\n",
       " 'PAM16': tensor(1.1858, device='cuda:0'),\n",
       " 'UBA2': tensor(1.2095, device='cuda:0'),\n",
       " 'SMG7': tensor(1.2120, device='cuda:0'),\n",
       " 'GAR1': tensor(1.1174, device='cuda:0'),\n",
       " 'NAA15': tensor(1.1762, device='cuda:0'),\n",
       " 'SRFBP1': tensor(1.2617, device='cuda:0'),\n",
       " 'PDRG1': tensor(1.1183, device='cuda:0'),\n",
       " 'RMI1': tensor(1.2542, device='cuda:0'),\n",
       " 'RPL26': tensor(1.3951, device='cuda:0'),\n",
       " 'TRMT6': tensor(1.1581, device='cuda:0'),\n",
       " 'PHB2': tensor(1.3849, device='cuda:0'),\n",
       " 'DNAJA1': tensor(1.1583, device='cuda:0'),\n",
       " 'INTS3': tensor(1.1756, device='cuda:0'),\n",
       " 'TUFM': tensor(1.1450, device='cuda:0'),\n",
       " 'CHMP7': tensor(1.2578, device='cuda:0'),\n",
       " 'IWS1': tensor(1.1360, device='cuda:0'),\n",
       " 'FBXO42': tensor(1.1095, device='cuda:0'),\n",
       " 'SNRNP48': tensor(1.2715, device='cuda:0'),\n",
       " 'INTS10': tensor(1.2196, device='cuda:0'),\n",
       " 'TXNL4B': tensor(1.1427, device='cuda:0'),\n",
       " 'WDR46': tensor(1.2409, device='cuda:0'),\n",
       " 'CD2BP2': tensor(1.1314, device='cuda:0'),\n",
       " 'WDHD1': tensor(1.2313, device='cuda:0'),\n",
       " 'RPL37A': tensor(1.4928, device='cuda:0'),\n",
       " 'THOC1': tensor(1.2923, device='cuda:0'),\n",
       " 'DRG1': tensor(1.0334, device='cuda:0'),\n",
       " 'TIGD1': tensor(1.1613, device='cuda:0'),\n",
       " 'PRRC2A': tensor(1.2058, device='cuda:0'),\n",
       " 'STIL': tensor(1.1967, device='cuda:0'),\n",
       " 'PTGR2': tensor(1.2522, device='cuda:0'),\n",
       " 'ABCB7': tensor(1.2028, device='cuda:0'),\n",
       " 'ARPC4': tensor(1.2083, device='cuda:0'),\n",
       " 'MRPL9': tensor(1.2893, device='cuda:0'),\n",
       " 'CUL1': tensor(1.2260, device='cuda:0'),\n",
       " 'TARS2': tensor(1.1737, device='cuda:0'),\n",
       " 'MIPEP': tensor(1.2313, device='cuda:0'),\n",
       " 'DNAJC17': tensor(1.2480, device='cuda:0'),\n",
       " 'NRBP1': tensor(1.1704, device='cuda:0'),\n",
       " 'NUP133': tensor(1.1770, device='cuda:0'),\n",
       " 'GABPB1': tensor(1.2443, device='cuda:0'),\n",
       " 'TMEM127': tensor(1.2100, device='cuda:0'),\n",
       " 'ARL4D': tensor(1.2387, device='cuda:0'),\n",
       " 'PGK1': tensor(1.1967, device='cuda:0'),\n",
       " 'KIN': tensor(1.1952, device='cuda:0'),\n",
       " 'GMPPB': tensor(1.1728, device='cuda:0'),\n",
       " 'NSUN4': tensor(1.2079, device='cuda:0'),\n",
       " 'CCDC86': tensor(1.2980, device='cuda:0'),\n",
       " 'NAA35': tensor(1.1319, device='cuda:0'),\n",
       " 'CENPC': tensor(1.1421, device='cuda:0'),\n",
       " 'DNM1L': tensor(1.1392, device='cuda:0'),\n",
       " 'BRIX1': tensor(1.2219, device='cuda:0'),\n",
       " 'RRN3': tensor(1.1524, device='cuda:0'),\n",
       " 'PELP1': tensor(1.1721, device='cuda:0'),\n",
       " 'TMEM242': tensor(1.1091, device='cuda:0'),\n",
       " 'TFDP1': tensor(1.1059, device='cuda:0'),\n",
       " 'HDAC3': tensor(1.1977, device='cuda:0'),\n",
       " 'LTBP3': tensor(1.1327, device='cuda:0'),\n",
       " 'RPL30': tensor(1.3345, device='cuda:0'),\n",
       " 'PDCD5': tensor(1.0822, device='cuda:0'),\n",
       " 'MED7': tensor(1.2580, device='cuda:0'),\n",
       " 'ZMAT2': tensor(1.1222, device='cuda:0'),\n",
       " 'TSEN2': tensor(1.2141, device='cuda:0'),\n",
       " 'PHB': tensor(1.3158, device='cuda:0'),\n",
       " 'EMC4': tensor(1.2538, device='cuda:0'),\n",
       " 'MRPL39': tensor(1.1946, device='cuda:0'),\n",
       " 'MRPL24': tensor(1.1976, device='cuda:0'),\n",
       " 'GPN3': tensor(1.1996, device='cuda:0'),\n",
       " 'ZNF720': tensor(1.1856, device='cuda:0'),\n",
       " 'MARS': tensor(1.2796, device='cuda:0'),\n",
       " 'ZNHIT3': tensor(1.1848, device='cuda:0'),\n",
       " 'URB1': tensor(1.1550, device='cuda:0'),\n",
       " 'EXOSC4': tensor(1.2176, device='cuda:0'),\n",
       " 'PGS1': tensor(1.2525, device='cuda:0'),\n",
       " 'NUDCD3': tensor(1.1269, device='cuda:0'),\n",
       " 'HSD17B10': tensor(1.1202, device='cuda:0'),\n",
       " 'RABGGTA': tensor(1.2048, device='cuda:0'),\n",
       " 'COTL1': tensor(1.1680, device='cuda:0'),\n",
       " 'CEP68': tensor(1.1981, device='cuda:0'),\n",
       " 'NOM1': tensor(1.1375, device='cuda:0'),\n",
       " 'INTS2': tensor(1.4326, device='cuda:0'),\n",
       " 'NFS1': tensor(1.2349, device='cuda:0'),\n",
       " 'MLLT6': tensor(1.1549, device='cuda:0'),\n",
       " 'E2F6': tensor(1.1731, device='cuda:0'),\n",
       " 'RPL7L1': tensor(1.3801, device='cuda:0'),\n",
       " 'ZBTB17': tensor(1.1461, device='cuda:0'),\n",
       " 'LPIN1': tensor(1.1765, device='cuda:0'),\n",
       " 'EXOSC5': tensor(1.1852, device='cuda:0'),\n",
       " 'ABHD11': tensor(1.1838, device='cuda:0'),\n",
       " 'DDX27': tensor(1.1792, device='cuda:0'),\n",
       " 'SRRM1': tensor(1.1398, device='cuda:0'),\n",
       " 'ZDHHC7': tensor(1.1117, device='cuda:0'),\n",
       " 'QRSL1': tensor(1.1080, device='cuda:0'),\n",
       " 'INTS11': tensor(1.1149, device='cuda:0'),\n",
       " 'SLC16A5': tensor(1.1678, device='cuda:0'),\n",
       " 'ANAPC10': tensor(1.1532, device='cuda:0'),\n",
       " 'DKC1': tensor(1.2219, device='cuda:0'),\n",
       " 'SPOUT1': tensor(1.2809, device='cuda:0'),\n",
       " 'NVL': tensor(1.1103, device='cuda:0'),\n",
       " 'DOLK': tensor(1.2146, device='cuda:0'),\n",
       " 'SNAPC5': tensor(1.1527, device='cuda:0'),\n",
       " 'PTPN11': tensor(1.1870, device='cuda:0'),\n",
       " 'COPS3': tensor(1.2463, device='cuda:0'),\n",
       " 'EMC1': tensor(1.2011, device='cuda:0'),\n",
       " 'GSPT1': tensor(1.2950, device='cuda:0'),\n",
       " 'CS': tensor(1.1296, device='cuda:0'),\n",
       " 'INO80B': tensor(1.2310, device='cuda:0'),\n",
       " 'BTAF1': tensor(1.1957, device='cuda:0'),\n",
       " 'ISCA2': tensor(1.1134, device='cuda:0'),\n",
       " 'EIF2B1': tensor(1.1832, device='cuda:0'),\n",
       " 'HARS': tensor(1.1885, device='cuda:0'),\n",
       " 'PRC1': tensor(1.2453, device='cuda:0'),\n",
       " 'INPPL1': tensor(1.2164, device='cuda:0'),\n",
       " 'SF3B5': tensor(1.4074, device='cuda:0'),\n",
       " 'RPS8': tensor(1.4478, device='cuda:0'),\n",
       " 'GNPNAT1': tensor(1.2356, device='cuda:0'),\n",
       " 'MCL1': tensor(1.1478, device='cuda:0'),\n",
       " 'TINF2': tensor(1.2007, device='cuda:0'),\n",
       " 'EXOC7': tensor(1.1198, device='cuda:0'),\n",
       " 'H2AFZ': tensor(1.1612, device='cuda:0'),\n",
       " 'GTF3C6': tensor(1.1251, device='cuda:0'),\n",
       " 'POGZ': tensor(1.2557, device='cuda:0'),\n",
       " 'TBCA': tensor(1.1953, device='cuda:0'),\n",
       " 'SNRNP25': tensor(1.3194, device='cuda:0'),\n",
       " 'RPS26': tensor(1.3432, device='cuda:0'),\n",
       " 'RCL1': tensor(1.2232, device='cuda:0'),\n",
       " 'GTF2H3': tensor(1.3320, device='cuda:0'),\n",
       " 'SETX': tensor(1.1999, device='cuda:0'),\n",
       " 'PES1': tensor(1.2488, device='cuda:0'),\n",
       " 'DDX20': tensor(1.2439, device='cuda:0'),\n",
       " 'TRAPPC1': tensor(1.0799, device='cuda:0'),\n",
       " 'CMTR1': tensor(1.2094, device='cuda:0'),\n",
       " 'RSL24D1': tensor(1.2757, device='cuda:0'),\n",
       " 'POLR3F': tensor(1.2306, device='cuda:0'),\n",
       " 'POLL': tensor(1.0939, device='cuda:0'),\n",
       " 'UTP6': tensor(1.1795, device='cuda:0'),\n",
       " 'RPL23A': tensor(1.2306, device='cuda:0'),\n",
       " 'NUB1': tensor(1.1817, device='cuda:0'),\n",
       " 'ANAPC5': tensor(1.2311, device='cuda:0'),\n",
       " 'TADA1': tensor(1.1834, device='cuda:0'),\n",
       " 'BMS1': tensor(1.2160, device='cuda:0'),\n",
       " 'INTS14': tensor(1.1275, device='cuda:0'),\n",
       " 'NOS1AP': tensor(1.1144, device='cuda:0'),\n",
       " 'RNASEH2C': tensor(1.1038, device='cuda:0'),\n",
       " 'GSK3B': tensor(1.1838, device='cuda:0'),\n",
       " 'HUWE1': tensor(1.1382, device='cuda:0'),\n",
       " 'DBR1': tensor(1.2377, device='cuda:0'),\n",
       " 'MED29': tensor(1.1220, device='cuda:0'),\n",
       " 'SEPSECS': tensor(1.1131, device='cuda:0'),\n",
       " 'MYBL2': tensor(1.1696, device='cuda:0'),\n",
       " 'NDUFA6': tensor(1.2847, device='cuda:0'),\n",
       " 'TAF13': tensor(1.1320, device='cuda:0'),\n",
       " 'FGFR1OP': tensor(1.2064, device='cuda:0'),\n",
       " 'PPP1R8': tensor(1.2426, device='cuda:0'),\n",
       " 'CDK2': tensor(1.2101, device='cuda:0'),\n",
       " 'CCND3': tensor(1.1291, device='cuda:0'),\n",
       " 'GCLC': tensor(1.1951, device='cuda:0'),\n",
       " 'DCTN2': tensor(1.2019, device='cuda:0'),\n",
       " 'CDC42': tensor(1.1138, device='cuda:0'),\n",
       " 'ATP6V1F': tensor(1.3128, device='cuda:0'),\n",
       " 'PSAT1': tensor(1.1704, device='cuda:0'),\n",
       " 'WDR70': tensor(1.2144, device='cuda:0'),\n",
       " 'FBLIM1': tensor(1.0959, device='cuda:0'),\n",
       " 'SHQ1': tensor(1.1476, device='cuda:0'),\n",
       " 'MED26': tensor(1.2535, device='cuda:0'),\n",
       " 'NLE1': tensor(1.3951, device='cuda:0'),\n",
       " 'UBQLN4': tensor(1.2623, device='cuda:0'),\n",
       " 'PSME2': tensor(1.1710, device='cuda:0'),\n",
       " 'SKP1': tensor(1.1948, device='cuda:0'),\n",
       " 'PTEN': tensor(1.1206, device='cuda:0'),\n",
       " 'BAP1': tensor(1.1571, device='cuda:0'),\n",
       " 'TMEM199': tensor(1.2665, device='cuda:0'),\n",
       " 'RPL28': tensor(1.2441, device='cuda:0'),\n",
       " 'NUP54': tensor(1.3077, device='cuda:0'),\n",
       " 'HMGB3': tensor(1.2629, device='cuda:0'),\n",
       " 'ORC5': tensor(1.1297, device='cuda:0'),\n",
       " 'AKIRIN2': tensor(1.1509, device='cuda:0'),\n",
       " 'RAC1': tensor(1.2600, device='cuda:0'),\n",
       " 'TAF6': tensor(1.1408, device='cuda:0'),\n",
       " 'EIF2S3': tensor(1.6357, device='cuda:0'),\n",
       " 'TTK': tensor(1.2049, device='cuda:0'),\n",
       " 'TMEM214': tensor(1.1200, device='cuda:0'),\n",
       " 'MCM2': tensor(1.1837, device='cuda:0'),\n",
       " 'ORC3': tensor(1.2780, device='cuda:0'),\n",
       " 'CMTR2': tensor(1.2036, device='cuda:0'),\n",
       " 'NFYB': tensor(1.3507, device='cuda:0'),\n",
       " 'CENPN': tensor(1.2458, device='cuda:0'),\n",
       " 'SDHAF2': tensor(1.1438, device='cuda:0'),\n",
       " 'RPS14': tensor(1.2393, device='cuda:0'),\n",
       " 'EIF2B5': tensor(1.6642, device='cuda:0'),\n",
       " 'PPP1R11': tensor(1.1946, device='cuda:0'),\n",
       " 'ITGB1BP1': tensor(1.2410, device='cuda:0'),\n",
       " 'SNRPC': tensor(1.3752, device='cuda:0'),\n",
       " 'SPATA5L1': tensor(1.2555, device='cuda:0'),\n",
       " 'U2SURP': tensor(1.3225, device='cuda:0'),\n",
       " 'RBM10': tensor(1.1181, device='cuda:0'),\n",
       " 'KDM6A': tensor(1.1962, device='cuda:0'),\n",
       " 'RNF8': tensor(1.1191, device='cuda:0'),\n",
       " 'DCUN1D5': tensor(1.1920, device='cuda:0'),\n",
       " 'NKAP': tensor(1.3226, device='cuda:0'),\n",
       " 'SUPT16H': tensor(1.3454, device='cuda:0'),\n",
       " 'RPL35': tensor(1.4596, device='cuda:0'),\n",
       " 'non-targeting': tensor(1.1008, device='cuda:0'),\n",
       " 'ESF1': tensor(1.1102, device='cuda:0'),\n",
       " 'CLASRP': tensor(1.0988, device='cuda:0'),\n",
       " 'DHPS': tensor(1.1508, device='cuda:0'),\n",
       " 'CENPT': tensor(1.1377, device='cuda:0'),\n",
       " 'MED17': tensor(1.2137, device='cuda:0')}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_list = list(set(hepg2_real.obs['gene']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 1459 × 2000\n",
       "    obs: 'gene', 'cell_type', 'ct_gem_group', 'pert_cell_barcode', 'ctrl_cell_barcode'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hepg2_pred[hepg2_pred.obs['gene']=='non-targeting']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import r2_score\n",
    "#x, y = scrnas_pred[0].mean(axis=0).detach().cpu().numpy(),case.obsm['VAE_latent'].mean(axis=0)\n",
    "def return_metrics(x, y):\n",
    "    return r2_score(x.mean(axis=0), y.mean(axis=0)), pearsonr(x.mean(axis=0), y.mean(axis=0))[0], mmd_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene_list = config['fewshot']['replogle_proper.hepg2']['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(state_Data[(state_Data.obs['gene'].isin(test_gene_list))&(state_Data.obs['cell_line']=='hepg2')].obs['gene']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_eval import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 38.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing cell type: jurkat\n",
      "Cell type: jurkat, Perturbation data shape: (96, 6642), Control data shape: (200, 6642)\n",
      "Cell type: jurkat, Perturbation latent shape: torch.Size([96, 512])\n",
      "Cell type: jurkat, Perturbation latent shape: torch.Size([96, 512]), Control latent shape: torch.Size([200, 512])\n",
      "Cell type: jurkat, Direction shape: torch.Size([512])\n",
      "Processing cell type: k562\n",
      "Cell type: k562, Perturbation data shape: (0, 6642), Control data shape: (200, 6642)\n",
      "Skipping cell type: k562 due to insufficient data.\n",
      "Processing cell type: rpe1\n",
      "Cell type: rpe1, Perturbation data shape: (30, 6642), Control data shape: (200, 6642)\n",
      "Cell type: rpe1, Perturbation latent shape: torch.Size([30, 512])\n",
      "Cell type: rpe1, Perturbation latent shape: torch.Size([30, 512]), Control latent shape: torch.Size([200, 512])\n",
      "Cell type: rpe1, Direction shape: torch.Size([512])\n",
      "Processing cell type: hepg2\n",
      "Cell type: hepg2, Perturbation data shape: (54, 6642), Control data shape: (200, 6642)\n",
      "Cell type: hepg2, Perturbation latent shape: torch.Size([54, 512])\n",
      "Cell type: hepg2, Perturbation latent shape: torch.Size([54, 512]), Control latent shape: torch.Size([200, 512])\n",
      "Cell type: hepg2, Direction shape: torch.Size([512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#拿ttf2作为例子\n",
    "import torch\n",
    "perturb, control_label =  \"RPS8\", \"non-targeting\"\n",
    "perturb_state_data = state_Data[state_Data.obs['gene'] == perturb]\n",
    "perturb_direction_dict = {}\n",
    "perturb_profile_dict = {}\n",
    "control_profile_dict = {}\n",
    "z_perturb_dict = {}\n",
    "z_control_dict = {}\n",
    "from tqdm import tqdm \n",
    "for cell_type in tqdm(cell_type_list, position=0):\n",
    "    print(f\"Processing cell type: {cell_type}\")\n",
    "    celltype_perturb_Data = perturb_state_data[perturb_state_data.obs['cell_line'] == cell_type]\n",
    "    control_Data = state_Data[(state_Data.obs['gene'] == control_label)&(state_Data.obs['cell_line'] == cell_type)]\n",
    "    print(f\"Cell type: {cell_type}, Perturbation data shape: {celltype_perturb_Data.shape}, Control data shape: {control_Data.shape}\")\n",
    "    if celltype_perturb_Data.shape[0] == 0 or control_Data.shape[0] == 0:\n",
    "        print(f\"Skipping cell type: {cell_type} due to insufficient data.\")\n",
    "        continue\n",
    "    z_perturb = sampler.model.encoder.forward(\n",
    "        x_start = torch.tensor(celltype_perturb_Data[:, state_Data.var['highly_variable']].X.toarray(), dtype=torch.float32).to('cuda'),\n",
    "        perturb_label = torch.tensor(np.stack(celltype_perturb_Data.obs['perturb_label'].values), dtype=torch.int32).to('cuda'),\n",
    "        batch = torch.tensor(np.stack(celltype_perturb_Data.obs['batch_label'].values), dtype=torch.int32).to('cuda'),\n",
    "        cell_type = torch.tensor(np.stack(celltype_perturb_Data.obs['cell_line_label'].values), dtype=torch.int32).to('cuda')\n",
    "    )\n",
    "    print(f\"Cell type: {cell_type}, Perturbation latent shape: {z_perturb.shape}\")\n",
    "    z_control = sampler.model.encoder.forward(\n",
    "        x_start = torch.tensor(control_Data[:, state_Data.var['highly_variable']].X.toarray(), dtype=torch.float32).to('cuda'),\n",
    "        perturb_label = torch.tensor(np.stack(control_Data.obs['perturb_label'].values), dtype=torch.int32).to('cuda'),\n",
    "        batch = torch.tensor(np.stack(control_Data.obs['batch_label'].values), dtype=torch.int32).to('cuda'),\n",
    "        cell_type = torch.tensor(np.stack(control_Data.obs['cell_line_label'].values), dtype=torch.int32).to('cuda')\n",
    "    )\n",
    "    print(f\"Cell type: {cell_type}, Perturbation latent shape: {z_perturb.shape}, Control latent shape: {z_control.shape}\")\n",
    "    direction = z_perturb.mean(axis=0) - z_control.mean(axis=0)\n",
    "    print(f\"Cell type: {cell_type}, Direction shape: {direction.shape}\")\n",
    "    perturb_direction_dict[cell_type] = direction\n",
    "    z_perturb_dict[cell_type] = z_perturb\n",
    "    z_control_dict[cell_type] = z_control\n",
    "    perturb_profile_dict[cell_type] = celltype_perturb_Data\n",
    "    control_profile_dict[cell_type] = control_Data\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([30, 512]), torch.Size([96, 512]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_perturb_dict['rpe1'].shape, z_perturb_dict['jurkat'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 看看latent在k562上的重建效果\n",
    "sample_interp_k562_perturb = sampler.pred(\n",
    "    z_sem = z_control_dict['rpe1'],\n",
    "    gene_size = sum(state_Data.var['highly_variable'])\n",
    ")\n",
    "r2_, pearsonr_ = sampler.cal_metric(sample_interp_k562_perturb,control_profile_dict['rpe1'][:, state_Data.var['highly_variable']] )\n",
    "# import MMD distance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-16.654558181762695, 0.4131721)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_, pearsonr_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y  = sample_interp_k562_perturb.to('cpu').detach().numpy(),control_profile_dict['rpe1'][:, state_Data.var['highly_variable']].X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.1213)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mmd_loss(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'k562'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m r2_score \n\u001b[32m      2\u001b[39m r2_score(\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mcontrol_profile_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mk562\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:, state_Data.var[\u001b[33m'\u001b[39m\u001b[33mhighly_variable\u001b[39m\u001b[33m'\u001b[39m]].X.toarray().flatten(),\n\u001b[32m      4\u001b[39m     sample_interp_k562_perturb.cpu().numpy().flatten()\n\u001b[32m      5\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: 'k562'"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "r2_score(\n",
    "    control_profile_dict['k562'][:, state_Data.var['highly_variable']].X.toarray().flatten(),\n",
    "    sample_interp_k562_perturb.cpu().numpy().flatten()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "test_data_gene1 = test_data[test_data.obs['gene']=='RPS8']\n",
    "z_control = z_control_dict['hepg2'][random.sample(range(len(z_control_dict['hepg2'])), test_data_gene1.shape[0]),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_comb_list = {item: sampler.interp_with_direction(z_sem_origin = z_control_dict['hepg2'],\n",
    "                                       gene_size = sum(state_Data.var['highly_variable']),\n",
    "                                       direction = perturb_direction_dict[item],\n",
    "                                       scale = 1,\n",
    "                                       add_noise_term = False #add noise if for interpolation\n",
    "                                      ) for item in cell_type_list if item in perturb_direction_dict.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cell type: jurkat, R2 Score: -6927.0693359375, MMD Loss: 2.7360951900482178\n",
      "Cell type: rpe1, R2 Score: -6878.76318359375, MMD Loss: 2.733095407485962\n",
      "Cell type: hepg2, R2 Score: -6989.48486328125, MMD Loss: 2.7404024600982666\n",
      "Cell type: jurkat, R2 Score: 0.4384259581565857, MMD Loss: 1.1788368225097656\n",
      "Cell type: rpe1, R2 Score: 0.5646163821220398, MMD Loss: 1.0753662586212158\n",
      "Cell type: hepg2, R2 Score: 1.0, MMD Loss: 0.0\n",
      "Cell type: jurkat, R2 Score: 0.3381509780883789, MMD Loss: 1.3714734315872192\n",
      "Cell type: rpe1, R2 Score: 0.4707518219947815, MMD Loss: 1.2071932554244995\n",
      "Cell type: hepg2, R2 Score: 0.8574005365371704, MMD Loss: 0.4565865993499756\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.metrics import r2_score\n",
    "y = test_data_gene1[:, state_Data.var['highly_variable']].X.toarray()\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = sample_comb_list[cell_type].to('cpu').detach().numpy()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = perturb_profile_dict[cell_type][:, state_Data.var['highly_variable']].X.toarray()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = control_profile_dict[cell_type][:, state_Data.var['highly_variable']].X.toarray()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    \n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute distance between control data and generated data\n",
      "Cell type: jurkat, R2 Score: -6409.35205078125, MMD Loss: 3.118868112564087\n",
      "Cell type: rpe1, R2 Score: -6364.76123046875, MMD Loss: 3.116450309753418\n",
      "Cell type: hepg2, R2 Score: -6467.39892578125, MMD Loss: 3.122645854949951\n",
      "Compute distance between control data and actual perturbation data\n",
      "Cell type: jurkat, R2 Score: 0.5103132724761963, MMD Loss: 1.056046962738037\n",
      "Cell type: rpe1, R2 Score: 0.5163160562515259, MMD Loss: 1.1418386697769165\n",
      "Cell type: hepg2, R2 Score: 0.8679935932159424, MMD Loss: 0.45658671855926514\n",
      "Compute distance between control data and control data\n",
      "Cell type: jurkat, R2 Score: 0.5611333847045898, MMD Loss: 1.0134795904159546\n",
      "Cell type: rpe1, R2 Score: 0.6404640674591064, MMD Loss: 0.9025882482528687\n",
      "Cell type: hepg2, R2 Score: 1.0, MMD Loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from sklearn.metrics import r2_score\n",
    "y = control_profile_dict['hepg2'][:, state_Data.var['highly_variable']].X.toarray()\n",
    "print(\"Compute distance between control data and generated data\")\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = sample_comb_list[cell_type].to('cpu').detach().numpy()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")\n",
    "print(\"Compute distance between control data and actual perturbation data\")\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = perturb_profile_dict[cell_type][:, state_Data.var['highly_variable']].X.toarray()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")\n",
    "print(\"Compute distance between control data and control data\")\n",
    "for cell_type in sample_comb_list.keys():\n",
    "    x = control_profile_dict[cell_type][:, state_Data.var['highly_variable']].X.toarray()\n",
    "    r2 = r2_score(\n",
    "        y.mean(axis=0),\n",
    "        x.mean(axis=0)\n",
    "    )\n",
    "    \n",
    "    mmd = mmd_loss(x, y)\n",
    "    print(f\"Cell type: {cell_type}, R2 Score: {r2}, MMD Loss: {mmd.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/test_replogle/hepg2_holdout/eval_last.ckpt/adata_pred.h5ad')\n",
    "truth = ad.read_h5ad('/work/home/cryoem666/xyf/temp/pycharm/state/test_replogle/hepg2_holdout/eval_last.ckpt/adata_real.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77058756, 0.        , 0.        , ..., 3.2787578 , 0.77058756,\n",
       "        4.4716063 ],\n",
       "       [0.        , 1.305768  , 0.5143976 , ..., 2.716365  , 2.1281052 ,\n",
       "        4.0400352 ],\n",
       "       [0.6739177 , 0.27811354, 0.49547172, ..., 2.4766753 , 1.0728899 ,\n",
       "        3.9258983 ],\n",
       "       ...,\n",
       "       [0.45875692, 0.        , 0.45875692, ..., 2.850647  , 1.5024396 ,\n",
       "        4.433684  ],\n",
       "       [0.74850327, 0.74850327, 0.44270754, ..., 2.9924858 , 1.1717597 ,\n",
       "        4.1920652 ],\n",
       "       [1.0784274 , 0.6780468 , 1.0784274 , ..., 2.8616548 , 0.6780468 ,\n",
       "        4.4472556 ]], dtype=float32)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cell_eval import MetricsEvaluator\n",
    "evaluator = MetricsEvaluator(\n",
    "    adata_pred=pred_ct,\n",
    "    adata_real=real_ct,\n",
    "    de_pred=None,\n",
    "    de_real=None,\n",
    "    control_pert=\"non-targeting\",\n",
    "    pert_col=\"target\",\n",
    "    de_method=\"wilcoxon\",\n",
    "    num_threads=-1,\n",
    "    batch_size=100,\n",
    "    outdir=\"./cell-eval-outdir\",\n",
    "    allow_discrete=False,\n",
    "    prefix=None,\n",
    "    skip_de=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5518, 1.0223, 0.4321,  ..., 0.0127, 0.2057, 0.7264],\n",
       "        [0.7055, 0.7062, 0.7564,  ..., 0.0593, 0.0000, 1.0425],\n",
       "        [0.7644, 1.2055, 0.3125,  ..., 0.0699, 0.3330, 0.8380],\n",
       "        ...,\n",
       "        [0.9589, 1.4247, 0.5020,  ..., 0.0650, 0.0365, 0.5431],\n",
       "        [0.1778, 1.5413, 0.0811,  ..., 0.2136, 0.0000, 0.7665],\n",
       "        [0.8655, 1.1622, 0.5321,  ..., 0.0669, 0.0123, 0.7398]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cell_eval impor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4090, 0.6985, 1.1057,  ..., 0.0000, 0.6985, 2.5747],\n",
       "        [0.8084, 0.8084, 1.0530,  ..., 0.0000, 0.8084, 2.4489],\n",
       "        [0.5808, 0.5808, 0.0000,  ..., 0.5808, 0.5808, 1.5969],\n",
       "        ...,\n",
       "        [0.5166, 0.0000, 0.8555,  ..., 0.0000, 0.5166, 2.2099],\n",
       "        [0.0000, 0.7911, 0.0000,  ..., 0.0000, 1.2272, 1.2272],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 2.1731]])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(perturb_profile_dict['k562'][:, perturb_profile_dict['k562'].var['highly_variable']].X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_metric_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_dict = {}\n",
    "for item in cell_type_list: \n",
    "    for type in cell_type_list:\n",
    "        perturb_profile = torch.tensor(perturb_profile_dict[item][:, perturb_profile_dict[item].var['highly_variable']].X.toarray())\n",
    "        matrix_dict[(item, type)] = sampler.cal_metric(perturb_profile, control_profile_dict[type][:, control_profile_dict[type].var['highly_variable']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_type = 'hepg2'\n",
    "cell_type_data = state_Data[state_Data.obs['cell_line']==cell_type]\n",
    "matrix_dict_perturb = {}\n",
    "gene_list = set(cell_type_data.obs['gene'])\n",
    "gene_data = torch.tensor(cell_type_data[cell_type_data.obs['gene']=='non-targeting'][:, cell_type_data.var['highly_variable']].X.toarray())\n",
    "for type in gene_list: \n",
    "    matrix_dict_perturb[('non-targeting', type)] = sampler.cal_metric(gene_data, cell_type_data[cell_type_data.obs['gene']==type][:, cell_type_data.var['highly_variable']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('non-targeting', 'RPS8'): (0.8290762901306152, 0.91209257),\n",
       " ('non-targeting', 'CCT6A'): (0.894419252872467, 0.9497758),\n",
       " ('non-targeting', 'non-targeting'): (1.0, 1.0),\n",
       " ('non-targeting', 'HGS'): (0.905807375907898, 0.95416015),\n",
       " ('non-targeting', 'POGZ'): (0.9838405847549438, 0.9919827),\n",
       " ('non-targeting', 'TRAPPC4'): (0.9801661968231201, 0.9903984),\n",
       " ('non-targeting', 'RIOK1'): (0.9225167036056519, 0.96107495),\n",
       " ('non-targeting', 'ATP2A2'): (0.9802168011665344, 0.9907773),\n",
       " ('non-targeting', 'PTCD3'): (0.9760352969169617, 0.9884068),\n",
       " ('non-targeting', 'POLR2B'): (0.8579238653182983, 0.9283825)}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_dict_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('jurkat', 'jurkat'): (0.9882532954216003, 0.99437463),\n",
       " ('jurkat', 'k562'): (0.6175300478935242, 0.8205467),\n",
       " ('jurkat', 'rpe1'): (0.33593934774398804, 0.74484843),\n",
       " ('jurkat', 'hepg2'): (0.45138877630233765, 0.73489785),\n",
       " ('k562', 'jurkat'): (0.5508226156234741, 0.8077812),\n",
       " ('k562', 'k562'): (0.980702817440033, 0.99034506),\n",
       " ('k562', 'rpe1'): (-0.05782675743103027, 0.6352488),\n",
       " ('k562', 'hepg2'): (0.4683115482330322, 0.7432175),\n",
       " ('rpe1', 'jurkat'): (0.5514518618583679, 0.7467724),\n",
       " ('rpe1', 'k562'): (0.3809424638748169, 0.644668),\n",
       " ('rpe1', 'rpe1'): (0.9944376945495605, 0.9972677),\n",
       " ('rpe1', 'hepg2'): (0.7057881951332092, 0.84981686),\n",
       " ('hepg2', 'jurkat'): (0.4251304268836975, 0.73420304),\n",
       " ('hepg2', 'k562'): (0.4744534492492676, 0.7268021),\n",
       " ('hepg2', 'rpe1'): (0.5653258562088013, 0.8596075),\n",
       " ('hepg2', 'hepg2'): (0.9839951992034912, 0.9919827)}"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9664002656936646, 0.9851414)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_data = state_Data[(state_Data.obs['gene']=='POGZ')&(state_Data.obs['cell_line']=='hepg2')]\n",
    "sampler.cal_metric(sample_comb_list['k562'], cell_data[:, cell_data.var['highly_variable']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.969586193561554, 0.9848137)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler.cal_metric(sample_comb, state_Data[:37, state_Data.var['highly_variable']] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gem_group</th>\n",
       "      <th>gene</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>transcript</th>\n",
       "      <th>gene_transcript</th>\n",
       "      <th>sgID_AB</th>\n",
       "      <th>mitopercent</th>\n",
       "      <th>UMI_count</th>\n",
       "      <th>z_gemgroup_UMI</th>\n",
       "      <th>cell_line</th>\n",
       "      <th>perturb_label</th>\n",
       "      <th>batch_label</th>\n",
       "      <th>cell_line_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_barcode</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TCCCACACAAGTCCAT-20</th>\n",
       "      <td>20</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10806_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00318|non-targeting_00877</td>\n",
       "      <td>0.078166</td>\n",
       "      <td>12998.0</td>\n",
       "      <td>-0.126799</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGAACATCTAGTGTG-16</th>\n",
       "      <td>16</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11012_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01721|non-targeting_01433</td>\n",
       "      <td>0.099047</td>\n",
       "      <td>12388.0</td>\n",
       "      <td>0.759928</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGGTATTAGGAACATT-42</th>\n",
       "      <td>42</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11025_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01813|non-targeting_00122</td>\n",
       "      <td>0.092756</td>\n",
       "      <td>12258.0</td>\n",
       "      <td>-0.521161</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TTGACCCCACGAAGAC-52</th>\n",
       "      <td>52</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10951_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01273|non-targeting_03357</td>\n",
       "      <td>0.131519</td>\n",
       "      <td>14918.0</td>\n",
       "      <td>0.026687</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GAGGGATCACTCCGGA-42</th>\n",
       "      <td>42</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11271_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_03467|non-targeting_01317</td>\n",
       "      <td>0.022323</td>\n",
       "      <td>17336.0</td>\n",
       "      <td>0.131101</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGGATAATCCCTCTCC-18</th>\n",
       "      <td>18</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11208_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_02977|non-targeting_01146</td>\n",
       "      <td>0.096092</td>\n",
       "      <td>13383.0</td>\n",
       "      <td>0.638283</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGTTAGAGCATCTTG-8</th>\n",
       "      <td>8</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10771_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00164|non-targeting_00374</td>\n",
       "      <td>0.099374</td>\n",
       "      <td>18677.0</td>\n",
       "      <td>-0.044485</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCAATGACATTGACAC-50</th>\n",
       "      <td>50</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10967_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01376|non-targeting_00354</td>\n",
       "      <td>0.078363</td>\n",
       "      <td>19716.0</td>\n",
       "      <td>0.358782</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TATATCCTCATGCAGT-1</th>\n",
       "      <td>1</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10869_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00693|non-targeting_02043</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>15344.0</td>\n",
       "      <td>0.279445</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCGATGGCACAATGTC-48</th>\n",
       "      <td>48</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10829_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00483|non-targeting_03391</td>\n",
       "      <td>0.057458</td>\n",
       "      <td>15420.0</td>\n",
       "      <td>-0.052988</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATCACGTCAAGAGTA-6</th>\n",
       "      <td>6</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11265_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_03426|non-targeting_02982</td>\n",
       "      <td>0.099153</td>\n",
       "      <td>19606.0</td>\n",
       "      <td>0.569214</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTGGCAGGTTTCTATC-20</th>\n",
       "      <td>20</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11238_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_03171|non-targeting_03032</td>\n",
       "      <td>0.101273</td>\n",
       "      <td>11000.0</td>\n",
       "      <td>-0.433626</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CAACAACCACGTGTGC-39</th>\n",
       "      <td>39</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10784_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00215|non-targeting_02292</td>\n",
       "      <td>0.081076</td>\n",
       "      <td>31341.0</td>\n",
       "      <td>0.973277</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGAGCATCATAGACTC-39</th>\n",
       "      <td>39</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10916_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00982|non-targeting_03760</td>\n",
       "      <td>0.077753</td>\n",
       "      <td>42429.0</td>\n",
       "      <td>1.966027</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGTAACAGGTTCCGC-35</th>\n",
       "      <td>35</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10923_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01035|non-targeting_02622</td>\n",
       "      <td>0.071143</td>\n",
       "      <td>44207.0</td>\n",
       "      <td>0.214060</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TATCTTGTCGCCTTTG-49</th>\n",
       "      <td>49</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11256_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_03318|non-targeting_00221</td>\n",
       "      <td>0.064063</td>\n",
       "      <td>15672.0</td>\n",
       "      <td>-0.133303</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAGGATGTAGACACG-45</th>\n",
       "      <td>45</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10916_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00982|non-targeting_03760</td>\n",
       "      <td>0.101204</td>\n",
       "      <td>32884.0</td>\n",
       "      <td>1.516347</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGGAGGTCAAGTTCCA-20</th>\n",
       "      <td>20</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10759_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00081|non-targeting_03672</td>\n",
       "      <td>0.073135</td>\n",
       "      <td>18336.0</td>\n",
       "      <td>0.692942</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GCTGGGTAGTCTCCTC-13</th>\n",
       "      <td>13</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10806_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00318|non-targeting_00877</td>\n",
       "      <td>0.139451</td>\n",
       "      <td>14887.0</td>\n",
       "      <td>-0.244132</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CGAGGCTAGCTGTTAC-13</th>\n",
       "      <td>13</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11321_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_03731|non-targeting_02863</td>\n",
       "      <td>0.102686</td>\n",
       "      <td>12991.0</td>\n",
       "      <td>-0.471874</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCAGCCTTCTGCTCTG-48</th>\n",
       "      <td>48</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11048_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01948|non-targeting_02744</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>17200.0</td>\n",
       "      <td>0.196871</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATGGATGTATGAGAT-14</th>\n",
       "      <td>14</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10767_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00158|non-targeting_01160</td>\n",
       "      <td>0.113241</td>\n",
       "      <td>27234.0</td>\n",
       "      <td>-0.325671</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGGAATACAGACCATT-11</th>\n",
       "      <td>11</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10916_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00982|non-targeting_03760</td>\n",
       "      <td>0.082549</td>\n",
       "      <td>15627.0</td>\n",
       "      <td>0.470081</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CCTTGTGTCGGAGTGA-31</th>\n",
       "      <td>31</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10764_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00121|non-targeting_00339</td>\n",
       "      <td>0.094270</td>\n",
       "      <td>13822.0</td>\n",
       "      <td>-0.938998</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTATGGGTGCGGCTT-52</th>\n",
       "      <td>52</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10952_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01278|non-targeting_02363</td>\n",
       "      <td>0.098331</td>\n",
       "      <td>22414.0</td>\n",
       "      <td>1.179612</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATGGTTGGTCAAGGCA-33</th>\n",
       "      <td>33</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11175_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_02766|non-targeting_01799</td>\n",
       "      <td>0.100829</td>\n",
       "      <td>12308.0</td>\n",
       "      <td>-0.287659</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTGGGAAGTAACATAG-32</th>\n",
       "      <td>32</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10829_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00483|non-targeting_03391</td>\n",
       "      <td>0.085579</td>\n",
       "      <td>36855.0</td>\n",
       "      <td>-0.108636</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACGATCAAGCCTTGAT-22</th>\n",
       "      <td>22</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10995_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01600|non-targeting_01113</td>\n",
       "      <td>0.119612</td>\n",
       "      <td>34612.0</td>\n",
       "      <td>2.404022</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCTCACGAGGCGTCCT-40</th>\n",
       "      <td>40</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10799_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00289|non-targeting_00015</td>\n",
       "      <td>0.136993</td>\n",
       "      <td>6358.0</td>\n",
       "      <td>-0.983491</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAGACAAGTGGATGAC-54</th>\n",
       "      <td>54</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10759_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00081|non-targeting_03672</td>\n",
       "      <td>0.112797</td>\n",
       "      <td>14894.0</td>\n",
       "      <td>-0.146579</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ATTCCTACACCTCTAC-33</th>\n",
       "      <td>33</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11164_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_02668|non-targeting_03017</td>\n",
       "      <td>0.107833</td>\n",
       "      <td>15524.0</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAACGACCACGGTAGA-3</th>\n",
       "      <td>3</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11073_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_02080|non-targeting_00151</td>\n",
       "      <td>0.102951</td>\n",
       "      <td>24837.0</td>\n",
       "      <td>1.415807</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GGATCTAAGTGGCAGT-29</th>\n",
       "      <td>29</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>11186_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_02819|non-targeting_01549</td>\n",
       "      <td>0.087992</td>\n",
       "      <td>16331.0</td>\n",
       "      <td>0.352531</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TGCAGTAGTTACGGAG-52</th>\n",
       "      <td>52</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10922_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_01030|non-targeting_02990</td>\n",
       "      <td>0.109006</td>\n",
       "      <td>11192.0</td>\n",
       "      <td>-0.546392</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TCATGTTGTCGACTTA-27</th>\n",
       "      <td>27</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10758_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00077|non-targeting_01678</td>\n",
       "      <td>0.062009</td>\n",
       "      <td>7886.0</td>\n",
       "      <td>-1.233754</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TACCTCGAGATACGAT-55</th>\n",
       "      <td>55</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10784_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00215|non-targeting_02292</td>\n",
       "      <td>0.081205</td>\n",
       "      <td>25602.0</td>\n",
       "      <td>-0.880880</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GATTCGAAGTCAACAA-55</th>\n",
       "      <td>55</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>non-targeting</td>\n",
       "      <td>10786_non-targeting_non-targeting_non-targeting</td>\n",
       "      <td>non-targeting_00218|non-targeting_00004</td>\n",
       "      <td>0.075342</td>\n",
       "      <td>27886.0</td>\n",
       "      <td>-0.753532</td>\n",
       "      <td>hepg2</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     gem_group           gene        gene_id     transcript  \\\n",
       "cell_barcode                                                                  \n",
       "TCCCACACAAGTCCAT-20         20  non-targeting  non-targeting  non-targeting   \n",
       "AAGAACATCTAGTGTG-16         16  non-targeting  non-targeting  non-targeting   \n",
       "GGGTATTAGGAACATT-42         42  non-targeting  non-targeting  non-targeting   \n",
       "TTGACCCCACGAAGAC-52         52  non-targeting  non-targeting  non-targeting   \n",
       "GAGGGATCACTCCGGA-42         42  non-targeting  non-targeting  non-targeting   \n",
       "AGGATAATCCCTCTCC-18         18  non-targeting  non-targeting  non-targeting   \n",
       "GTGTTAGAGCATCTTG-8           8  non-targeting  non-targeting  non-targeting   \n",
       "CCAATGACATTGACAC-50         50  non-targeting  non-targeting  non-targeting   \n",
       "TATATCCTCATGCAGT-1           1  non-targeting  non-targeting  non-targeting   \n",
       "CCGATGGCACAATGTC-48         48  non-targeting  non-targeting  non-targeting   \n",
       "AATCACGTCAAGAGTA-6           6  non-targeting  non-targeting  non-targeting   \n",
       "CTGGCAGGTTTCTATC-20         20  non-targeting  non-targeting  non-targeting   \n",
       "CAACAACCACGTGTGC-39         39  non-targeting  non-targeting  non-targeting   \n",
       "TGAGCATCATAGACTC-39         39  non-targeting  non-targeting  non-targeting   \n",
       "ACGTAACAGGTTCCGC-35         35  non-targeting  non-targeting  non-targeting   \n",
       "TATCTTGTCGCCTTTG-49         49  non-targeting  non-targeting  non-targeting   \n",
       "AAAGGATGTAGACACG-45         45  non-targeting  non-targeting  non-targeting   \n",
       "AGGAGGTCAAGTTCCA-20         20  non-targeting  non-targeting  non-targeting   \n",
       "GCTGGGTAGTCTCCTC-13         13  non-targeting  non-targeting  non-targeting   \n",
       "CGAGGCTAGCTGTTAC-13         13  non-targeting  non-targeting  non-targeting   \n",
       "TCAGCCTTCTGCTCTG-48         48  non-targeting  non-targeting  non-targeting   \n",
       "CATGGATGTATGAGAT-14         14  non-targeting  non-targeting  non-targeting   \n",
       "AGGAATACAGACCATT-11         11  non-targeting  non-targeting  non-targeting   \n",
       "CCTTGTGTCGGAGTGA-31         31  non-targeting  non-targeting  non-targeting   \n",
       "ACTATGGGTGCGGCTT-52         52  non-targeting  non-targeting  non-targeting   \n",
       "ATGGTTGGTCAAGGCA-33         33  non-targeting  non-targeting  non-targeting   \n",
       "GTGGGAAGTAACATAG-32         32  non-targeting  non-targeting  non-targeting   \n",
       "ACGATCAAGCCTTGAT-22         22  non-targeting  non-targeting  non-targeting   \n",
       "TCTCACGAGGCGTCCT-40         40  non-targeting  non-targeting  non-targeting   \n",
       "AAGACAAGTGGATGAC-54         54  non-targeting  non-targeting  non-targeting   \n",
       "ATTCCTACACCTCTAC-33         33  non-targeting  non-targeting  non-targeting   \n",
       "TAACGACCACGGTAGA-3           3  non-targeting  non-targeting  non-targeting   \n",
       "GGATCTAAGTGGCAGT-29         29  non-targeting  non-targeting  non-targeting   \n",
       "TGCAGTAGTTACGGAG-52         52  non-targeting  non-targeting  non-targeting   \n",
       "TCATGTTGTCGACTTA-27         27  non-targeting  non-targeting  non-targeting   \n",
       "TACCTCGAGATACGAT-55         55  non-targeting  non-targeting  non-targeting   \n",
       "GATTCGAAGTCAACAA-55         55  non-targeting  non-targeting  non-targeting   \n",
       "\n",
       "                                                     gene_transcript  \\\n",
       "cell_barcode                                                           \n",
       "TCCCACACAAGTCCAT-20  10806_non-targeting_non-targeting_non-targeting   \n",
       "AAGAACATCTAGTGTG-16  11012_non-targeting_non-targeting_non-targeting   \n",
       "GGGTATTAGGAACATT-42  11025_non-targeting_non-targeting_non-targeting   \n",
       "TTGACCCCACGAAGAC-52  10951_non-targeting_non-targeting_non-targeting   \n",
       "GAGGGATCACTCCGGA-42  11271_non-targeting_non-targeting_non-targeting   \n",
       "AGGATAATCCCTCTCC-18  11208_non-targeting_non-targeting_non-targeting   \n",
       "GTGTTAGAGCATCTTG-8   10771_non-targeting_non-targeting_non-targeting   \n",
       "CCAATGACATTGACAC-50  10967_non-targeting_non-targeting_non-targeting   \n",
       "TATATCCTCATGCAGT-1   10869_non-targeting_non-targeting_non-targeting   \n",
       "CCGATGGCACAATGTC-48  10829_non-targeting_non-targeting_non-targeting   \n",
       "AATCACGTCAAGAGTA-6   11265_non-targeting_non-targeting_non-targeting   \n",
       "CTGGCAGGTTTCTATC-20  11238_non-targeting_non-targeting_non-targeting   \n",
       "CAACAACCACGTGTGC-39  10784_non-targeting_non-targeting_non-targeting   \n",
       "TGAGCATCATAGACTC-39  10916_non-targeting_non-targeting_non-targeting   \n",
       "ACGTAACAGGTTCCGC-35  10923_non-targeting_non-targeting_non-targeting   \n",
       "TATCTTGTCGCCTTTG-49  11256_non-targeting_non-targeting_non-targeting   \n",
       "AAAGGATGTAGACACG-45  10916_non-targeting_non-targeting_non-targeting   \n",
       "AGGAGGTCAAGTTCCA-20  10759_non-targeting_non-targeting_non-targeting   \n",
       "GCTGGGTAGTCTCCTC-13  10806_non-targeting_non-targeting_non-targeting   \n",
       "CGAGGCTAGCTGTTAC-13  11321_non-targeting_non-targeting_non-targeting   \n",
       "TCAGCCTTCTGCTCTG-48  11048_non-targeting_non-targeting_non-targeting   \n",
       "CATGGATGTATGAGAT-14  10767_non-targeting_non-targeting_non-targeting   \n",
       "AGGAATACAGACCATT-11  10916_non-targeting_non-targeting_non-targeting   \n",
       "CCTTGTGTCGGAGTGA-31  10764_non-targeting_non-targeting_non-targeting   \n",
       "ACTATGGGTGCGGCTT-52  10952_non-targeting_non-targeting_non-targeting   \n",
       "ATGGTTGGTCAAGGCA-33  11175_non-targeting_non-targeting_non-targeting   \n",
       "GTGGGAAGTAACATAG-32  10829_non-targeting_non-targeting_non-targeting   \n",
       "ACGATCAAGCCTTGAT-22  10995_non-targeting_non-targeting_non-targeting   \n",
       "TCTCACGAGGCGTCCT-40  10799_non-targeting_non-targeting_non-targeting   \n",
       "AAGACAAGTGGATGAC-54  10759_non-targeting_non-targeting_non-targeting   \n",
       "ATTCCTACACCTCTAC-33  11164_non-targeting_non-targeting_non-targeting   \n",
       "TAACGACCACGGTAGA-3   11073_non-targeting_non-targeting_non-targeting   \n",
       "GGATCTAAGTGGCAGT-29  11186_non-targeting_non-targeting_non-targeting   \n",
       "TGCAGTAGTTACGGAG-52  10922_non-targeting_non-targeting_non-targeting   \n",
       "TCATGTTGTCGACTTA-27  10758_non-targeting_non-targeting_non-targeting   \n",
       "TACCTCGAGATACGAT-55  10784_non-targeting_non-targeting_non-targeting   \n",
       "GATTCGAAGTCAACAA-55  10786_non-targeting_non-targeting_non-targeting   \n",
       "\n",
       "                                                     sgID_AB  mitopercent  \\\n",
       "cell_barcode                                                                \n",
       "TCCCACACAAGTCCAT-20  non-targeting_00318|non-targeting_00877     0.078166   \n",
       "AAGAACATCTAGTGTG-16  non-targeting_01721|non-targeting_01433     0.099047   \n",
       "GGGTATTAGGAACATT-42  non-targeting_01813|non-targeting_00122     0.092756   \n",
       "TTGACCCCACGAAGAC-52  non-targeting_01273|non-targeting_03357     0.131519   \n",
       "GAGGGATCACTCCGGA-42  non-targeting_03467|non-targeting_01317     0.022323   \n",
       "AGGATAATCCCTCTCC-18  non-targeting_02977|non-targeting_01146     0.096092   \n",
       "GTGTTAGAGCATCTTG-8   non-targeting_00164|non-targeting_00374     0.099374   \n",
       "CCAATGACATTGACAC-50  non-targeting_01376|non-targeting_00354     0.078363   \n",
       "TATATCCTCATGCAGT-1   non-targeting_00693|non-targeting_02043     0.113725   \n",
       "CCGATGGCACAATGTC-48  non-targeting_00483|non-targeting_03391     0.057458   \n",
       "AATCACGTCAAGAGTA-6   non-targeting_03426|non-targeting_02982     0.099153   \n",
       "CTGGCAGGTTTCTATC-20  non-targeting_03171|non-targeting_03032     0.101273   \n",
       "CAACAACCACGTGTGC-39  non-targeting_00215|non-targeting_02292     0.081076   \n",
       "TGAGCATCATAGACTC-39  non-targeting_00982|non-targeting_03760     0.077753   \n",
       "ACGTAACAGGTTCCGC-35  non-targeting_01035|non-targeting_02622     0.071143   \n",
       "TATCTTGTCGCCTTTG-49  non-targeting_03318|non-targeting_00221     0.064063   \n",
       "AAAGGATGTAGACACG-45  non-targeting_00982|non-targeting_03760     0.101204   \n",
       "AGGAGGTCAAGTTCCA-20  non-targeting_00081|non-targeting_03672     0.073135   \n",
       "GCTGGGTAGTCTCCTC-13  non-targeting_00318|non-targeting_00877     0.139451   \n",
       "CGAGGCTAGCTGTTAC-13  non-targeting_03731|non-targeting_02863     0.102686   \n",
       "TCAGCCTTCTGCTCTG-48  non-targeting_01948|non-targeting_02744     0.075581   \n",
       "CATGGATGTATGAGAT-14  non-targeting_00158|non-targeting_01160     0.113241   \n",
       "AGGAATACAGACCATT-11  non-targeting_00982|non-targeting_03760     0.082549   \n",
       "CCTTGTGTCGGAGTGA-31  non-targeting_00121|non-targeting_00339     0.094270   \n",
       "ACTATGGGTGCGGCTT-52  non-targeting_01278|non-targeting_02363     0.098331   \n",
       "ATGGTTGGTCAAGGCA-33  non-targeting_02766|non-targeting_01799     0.100829   \n",
       "GTGGGAAGTAACATAG-32  non-targeting_00483|non-targeting_03391     0.085579   \n",
       "ACGATCAAGCCTTGAT-22  non-targeting_01600|non-targeting_01113     0.119612   \n",
       "TCTCACGAGGCGTCCT-40  non-targeting_00289|non-targeting_00015     0.136993   \n",
       "AAGACAAGTGGATGAC-54  non-targeting_00081|non-targeting_03672     0.112797   \n",
       "ATTCCTACACCTCTAC-33  non-targeting_02668|non-targeting_03017     0.107833   \n",
       "TAACGACCACGGTAGA-3   non-targeting_02080|non-targeting_00151     0.102951   \n",
       "GGATCTAAGTGGCAGT-29  non-targeting_02819|non-targeting_01549     0.087992   \n",
       "TGCAGTAGTTACGGAG-52  non-targeting_01030|non-targeting_02990     0.109006   \n",
       "TCATGTTGTCGACTTA-27  non-targeting_00077|non-targeting_01678     0.062009   \n",
       "TACCTCGAGATACGAT-55  non-targeting_00215|non-targeting_02292     0.081205   \n",
       "GATTCGAAGTCAACAA-55  non-targeting_00218|non-targeting_00004     0.075342   \n",
       "\n",
       "                     UMI_count  z_gemgroup_UMI cell_line perturb_label  \\\n",
       "cell_barcode                                                             \n",
       "TCCCACACAAGTCCAT-20    12998.0       -0.126799     hepg2            10   \n",
       "AAGAACATCTAGTGTG-16    12388.0        0.759928     hepg2            10   \n",
       "GGGTATTAGGAACATT-42    12258.0       -0.521161     hepg2            10   \n",
       "TTGACCCCACGAAGAC-52    14918.0        0.026687     hepg2            10   \n",
       "GAGGGATCACTCCGGA-42    17336.0        0.131101     hepg2            10   \n",
       "AGGATAATCCCTCTCC-18    13383.0        0.638283     hepg2            10   \n",
       "GTGTTAGAGCATCTTG-8     18677.0       -0.044485     hepg2            10   \n",
       "CCAATGACATTGACAC-50    19716.0        0.358782     hepg2            10   \n",
       "TATATCCTCATGCAGT-1     15344.0        0.279445     hepg2            10   \n",
       "CCGATGGCACAATGTC-48    15420.0       -0.052988     hepg2            10   \n",
       "AATCACGTCAAGAGTA-6     19606.0        0.569214     hepg2            10   \n",
       "CTGGCAGGTTTCTATC-20    11000.0       -0.433626     hepg2            10   \n",
       "CAACAACCACGTGTGC-39    31341.0        0.973277     hepg2            10   \n",
       "TGAGCATCATAGACTC-39    42429.0        1.966027     hepg2            10   \n",
       "ACGTAACAGGTTCCGC-35    44207.0        0.214060     hepg2            10   \n",
       "TATCTTGTCGCCTTTG-49    15672.0       -0.133303     hepg2            10   \n",
       "AAAGGATGTAGACACG-45    32884.0        1.516347     hepg2            10   \n",
       "AGGAGGTCAAGTTCCA-20    18336.0        0.692942     hepg2            10   \n",
       "GCTGGGTAGTCTCCTC-13    14887.0       -0.244132     hepg2            10   \n",
       "CGAGGCTAGCTGTTAC-13    12991.0       -0.471874     hepg2            10   \n",
       "TCAGCCTTCTGCTCTG-48    17200.0        0.196871     hepg2            10   \n",
       "CATGGATGTATGAGAT-14    27234.0       -0.325671     hepg2            10   \n",
       "AGGAATACAGACCATT-11    15627.0        0.470081     hepg2            10   \n",
       "CCTTGTGTCGGAGTGA-31    13822.0       -0.938998     hepg2            10   \n",
       "ACTATGGGTGCGGCTT-52    22414.0        1.179612     hepg2            10   \n",
       "ATGGTTGGTCAAGGCA-33    12308.0       -0.287659     hepg2            10   \n",
       "GTGGGAAGTAACATAG-32    36855.0       -0.108636     hepg2            10   \n",
       "ACGATCAAGCCTTGAT-22    34612.0        2.404022     hepg2            10   \n",
       "TCTCACGAGGCGTCCT-40     6358.0       -0.983491     hepg2            10   \n",
       "AAGACAAGTGGATGAC-54    14894.0       -0.146579     hepg2            10   \n",
       "ATTCCTACACCTCTAC-33    15524.0        0.148970     hepg2            10   \n",
       "TAACGACCACGGTAGA-3     24837.0        1.415807     hepg2            10   \n",
       "GGATCTAAGTGGCAGT-29    16331.0        0.352531     hepg2            10   \n",
       "TGCAGTAGTTACGGAG-52    11192.0       -0.546392     hepg2            10   \n",
       "TCATGTTGTCGACTTA-27     7886.0       -1.233754     hepg2            10   \n",
       "TACCTCGAGATACGAT-55    25602.0       -0.880880     hepg2            10   \n",
       "GATTCGAAGTCAACAA-55    27886.0       -0.753532     hepg2            10   \n",
       "\n",
       "                     batch_label cell_line_label  \n",
       "cell_barcode                                      \n",
       "TCCCACACAAGTCCAT-20           19               0  \n",
       "AAGAACATCTAGTGTG-16           15               0  \n",
       "GGGTATTAGGAACATT-42           41               0  \n",
       "TTGACCCCACGAAGAC-52           51               0  \n",
       "GAGGGATCACTCCGGA-42           41               0  \n",
       "AGGATAATCCCTCTCC-18           17               0  \n",
       "GTGTTAGAGCATCTTG-8             7               0  \n",
       "CCAATGACATTGACAC-50           49               0  \n",
       "TATATCCTCATGCAGT-1             0               0  \n",
       "CCGATGGCACAATGTC-48           47               0  \n",
       "AATCACGTCAAGAGTA-6             5               0  \n",
       "CTGGCAGGTTTCTATC-20           19               0  \n",
       "CAACAACCACGTGTGC-39           38               0  \n",
       "TGAGCATCATAGACTC-39           38               0  \n",
       "ACGTAACAGGTTCCGC-35           34               0  \n",
       "TATCTTGTCGCCTTTG-49           48               0  \n",
       "AAAGGATGTAGACACG-45           44               0  \n",
       "AGGAGGTCAAGTTCCA-20           19               0  \n",
       "GCTGGGTAGTCTCCTC-13           12               0  \n",
       "CGAGGCTAGCTGTTAC-13           12               0  \n",
       "TCAGCCTTCTGCTCTG-48           47               0  \n",
       "CATGGATGTATGAGAT-14           13               0  \n",
       "AGGAATACAGACCATT-11           10               0  \n",
       "CCTTGTGTCGGAGTGA-31           30               0  \n",
       "ACTATGGGTGCGGCTT-52           51               0  \n",
       "ATGGTTGGTCAAGGCA-33           32               0  \n",
       "GTGGGAAGTAACATAG-32           31               0  \n",
       "ACGATCAAGCCTTGAT-22           21               0  \n",
       "TCTCACGAGGCGTCCT-40           39               0  \n",
       "AAGACAAGTGGATGAC-54           53               0  \n",
       "ATTCCTACACCTCTAC-33           32               0  \n",
       "TAACGACCACGGTAGA-3             2               0  \n",
       "GGATCTAAGTGGCAGT-29           28               0  \n",
       "TGCAGTAGTTACGGAG-52           51               0  \n",
       "TCATGTTGTCGACTTA-27           26               0  \n",
       "TACCTCGAGATACGAT-55           54               0  \n",
       "GATTCGAAGTCAACAA-55           54               0  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_Data[:37, state_Data.var['highly_variable']].obs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([37, 201])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 37 × 201\n",
       "    obs: 'gem_group', 'gene', 'gene_id', 'transcript', 'gene_transcript', 'sgID_AB', 'mitopercent', 'UMI_count', 'z_gemgroup_UMI', 'cell_line', 'perturb_label', 'batch_label', 'cell_line_label'\n",
       "    var: 'highly_variable'\n",
       "    obsm: 'X_hvg'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_Data[:37, state_Data.var['highly_variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 37 × 201\n",
       "    obs: 'gem_group', 'gene', 'gene_id', 'transcript', 'gene_transcript', 'sgID_AB', 'mitopercent', 'UMI_count', 'z_gemgroup_UMI', 'cell_line', 'perturb_label', 'batch_label', 'cell_line_label'\n",
       "    var: 'highly_variable'\n",
       "    obsm: 'X_hvg'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_gene1[:, state_Data.var['highly_variable']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7282, 0.9856, 0.6788,  ..., 0.3601, 0.0000, 1.2772],\n",
       "        [0.1632, 0.7973, 0.2425,  ..., 0.1355, 0.4455, 1.0979],\n",
       "        [0.2565, 1.2333, 0.6216,  ..., 0.0000, 0.0631, 1.1449],\n",
       "        ...,\n",
       "        [1.0260, 1.0914, 0.3689,  ..., 0.0433, 0.0894, 1.1866],\n",
       "        [0.6659, 1.0609, 0.2292,  ..., 0.0139, 0.2113, 1.1310],\n",
       "        [0.3912, 1.1426, 0.3057,  ..., 0.2335, 0.0000, 1.1373]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_list = ['POGZ', 'RPS8']\n",
    "for gene in gene_list:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity between different cell types\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cell_types = list(perturb_direction_dict.keys())\n",
    "directions = torch.stack([perturb_direction_dict[ct] for ct in cell_types]).detach().cpu().numpy()\n",
    "similarity_matrix = cosine_similarity(directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.0000001 ,  0.18834874, -0.03933998,  0.24443385],\n",
       "       [ 0.18834874,  1.0000002 , -0.00648843,  0.01074759],\n",
       "       [-0.03933998, -0.00648843,  1.        ,  0.09405403],\n",
       "       [ 0.24443385,  0.01074759,  0.09405403,  0.99999994]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.99999994,  0.4493432 , -0.54073685,  0.3392582 ],\n",
       "       [ 0.4493432 ,  0.99999976, -0.3435316 ,  0.12021162],\n",
       "       [-0.54073685, -0.3435316 ,  1.0000001 , -0.64503545],\n",
       "       [ 0.3392582 ,  0.12021162, -0.64503545,  1.0000001 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_gene = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ct = tuple(config['fewshot'].keys())[0].split('.')[1]\n",
    "control_label = 'non-targeting'\n",
    "test_perturb = tuple(config['fewshot'].items())[0][1]['test']\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.model.encoder.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型包含的权重层／参数名称：\n",
      "time_embed.0.weight\n",
      "time_embed.0.bias\n",
      "time_embed.2.weight\n",
      "time_embed.2.bias\n",
      "mlp_blocks.0.fc1.weight\n",
      "mlp_blocks.0.fc1.bias\n",
      "mlp_blocks.0.fc2.weight\n",
      "mlp_blocks.0.fc2.bias\n",
      "mlp_blocks.0.layer_norm1.weight\n",
      "mlp_blocks.0.layer_norm1.bias\n",
      "mlp_blocks.0.layer_norm2.weight\n",
      "mlp_blocks.0.layer_norm2.bias\n",
      "mlp_blocks.0.time_dense.weight\n",
      "mlp_blocks.0.time_dense.bias\n",
      "mlp_blocks.1.fc1.weight\n",
      "mlp_blocks.1.fc1.bias\n",
      "mlp_blocks.1.fc2.weight\n",
      "mlp_blocks.1.fc2.bias\n",
      "mlp_blocks.1.layer_norm1.weight\n",
      "mlp_blocks.1.layer_norm1.bias\n",
      "mlp_blocks.1.layer_norm2.weight\n",
      "mlp_blocks.1.layer_norm2.bias\n",
      "mlp_blocks.1.time_dense.weight\n",
      "mlp_blocks.1.time_dense.bias\n",
      "mlp_blocks.2.fc1.weight\n",
      "mlp_blocks.2.fc1.bias\n",
      "mlp_blocks.2.fc2.weight\n",
      "mlp_blocks.2.fc2.bias\n",
      "mlp_blocks.2.layer_norm1.weight\n",
      "mlp_blocks.2.layer_norm1.bias\n",
      "mlp_blocks.2.layer_norm2.weight\n",
      "mlp_blocks.2.layer_norm2.bias\n",
      "mlp_blocks.2.time_dense.weight\n",
      "mlp_blocks.2.time_dense.bias\n",
      "input_layer.weight\n",
      "input_layer.bias\n",
      "output_layer.weight\n",
      "output_layer.bias\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 加载 checkpoint（如果显存有限可以用 map_location=\"cpu\"）\n",
    "ckpt = torch.load(\"/work/home/cryoem666/xyf/temp/pycharm/Squidiff/checkpoints/ours/model.pt\",\n",
    "                  map_location=\"cpu\")\n",
    "\n",
    "# 1. 如果是直接保存的 state_dict\n",
    "if isinstance(ckpt, dict) and all(isinstance(v, torch.Tensor) for v in ckpt.values()):\n",
    "    keys = ckpt.keys()\n",
    "# 2. 如果 checkpoint 是个 dict，里头有 'state_dict' 或类似 key\n",
    "elif isinstance(ckpt, dict) and \"state_dict\" in ckpt:\n",
    "    keys = ckpt[\"state_dict\"].keys()\n",
    "else:\n",
    "    # 其他情况，先看一下顶层 keys\n",
    "    print(\"checkpoint 顶层 keys:\", ckpt.keys())\n",
    "    # 假设第一个 key 对应的就是参数 dict\n",
    "    first = next(iter(ckpt.values()))\n",
    "    if isinstance(first, dict):\n",
    "        keys = first.keys()\n",
    "    else:\n",
    "        raise ValueError(\"无法识别 checkpoint 格式，请手动检查结构\")\n",
    "\n",
    "# 打印所有参数名\n",
    "print(\"模型包含的权重层／参数名称：\")\n",
    "for k in keys:\n",
    "    print(k)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_state",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
